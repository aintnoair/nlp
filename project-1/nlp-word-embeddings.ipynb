{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NLP Project - Word Embeddings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2af98235081195f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview:\n",
    "This project focuses on a reading comprehension using the BoolQ dataset and making use of word embeddings (word2vec) along with a two-layer classifier with ReLU activation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1839140469df69df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tools & Libraries:\n",
    "1. **Dataset:** BoolQ form Hugging Face datasets.\n",
    "2. **Word Embeddings:** Pre-trained word2vec embeddings.\n",
    "3. **Neural Network:** A 2-layer classifier with ReLU non-linearity.\n",
    "4. **Evaluation & Monitoring:** Weights & Biases for experiment tracking.\n",
    "5. **Framework:** PyTorch (for modelling)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7df6218b57a1b369"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "### Problem:\n",
    "A reading comprehension based on the BoolQ dataset.\n",
    "\n",
    "### Approach:\n",
    "Use word2vec embeddings with a classifier model.\n",
    "\n",
    "### Objective:\n",
    "Classify weather the answer to a give question based on context is \"yes\" or \"no\"."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "851eaf011678e5aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "Install the necessary libraries: \n",
    "- Hugging Face datasets\n",
    "- PyTorch\n",
    "- gensim\n",
    "- weights and biases\n",
    "- scikit-learn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3f9f3afdda462cf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "- Tokenize the dataset: Convert text to tokens compatible with the word2vec model.\n",
    "- embed the tokens using pre-trained word2vec embeddings (using gensim).\n",
    "- Handle out-of-vocabulary words by averaging word vectors or ignoring them.\n",
    "- prepare input for the model: Combine the question and context embeddings."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a3ac48fc942536a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Architecture\n",
    "- Input: Embedding size from word2vec\n",
    "- Layers:\n",
    "  - Layer 1: Fully connected layer with ReLu activation.\n",
    "  - Layer 2: Fully connected layer outputting two logits (for binary classification).\n",
    "- use softmax to convert logits into probabilities for final classification.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b8bd67a5e30d10a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'do iran and afghanistan speak the same language', 'answer': True, 'passage': 'Persian (/ˈpɜːrʒən, -ʃən/), also known by its endonym Farsi (فارسی fārsi (fɒːɾˈsiː) ( listen)), is one of the Western Iranian languages within the Indo-Iranian branch of the Indo-European language family. It is primarily spoken in Iran, Afghanistan (officially known as Dari since 1958), and Tajikistan (officially known as Tajiki since the Soviet era), and some other regions which historically were Persianate societies and considered part of Greater Iran. It is written in the Persian alphabet, a modified variant of the Arabic script, which itself evolved from the Aramaic alphabet.'}\n",
      "Number of training samples: 9427\n",
      "Number of validation samples: 3270\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('boolq')\n",
    "\n",
    "train_data = dataset['train']\n",
    "validation_data = dataset['validation']\n",
    "\n",
    "print(train_data[0])\n",
    "\n",
    "# View some basic statistics\n",
    "print(f\"Number of training samples: {len(train_data)}\")\n",
    "print(f\"Number of validation samples: {len(validation_data)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-28T15:02:09.115441Z",
     "start_time": "2024-09-28T15:02:05.056689Z"
    }
   },
   "id": "362d80d81a6f32c5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-28T15:11:45.161148Z",
     "start_time": "2024-09-28T15:11:45.158946Z"
    }
   },
   "id": "105e8569e49acdb5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-28T14:35:29.526980Z",
     "start_time": "2024-09-28T14:35:29.522634Z"
    }
   },
   "id": "c60ba7da2b130349"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-28T14:35:29.527225Z",
     "start_time": "2024-09-28T14:35:29.525102Z"
    }
   },
   "id": "96ccffaf6592fd49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-28T14:35:29.532086Z",
     "start_time": "2024-09-28T14:35:29.527621Z"
    }
   },
   "id": "a452cef44c0b64c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-28T14:35:29.532948Z",
     "start_time": "2024-09-28T14:35:29.530258Z"
    }
   },
   "id": "91957fa91d76ba93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-28T14:35:29.536587Z",
     "start_time": "2024-09-28T14:35:29.532770Z"
    }
   },
   "id": "e81252dde088b45e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9a9f127e6a6aa69f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
