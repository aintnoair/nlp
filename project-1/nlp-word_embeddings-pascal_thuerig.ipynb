{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af98235081195f5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# NLP - Word Embeddings - Pascal Thürig"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "Starting point for this project is the following key requirements:\n",
    "1. Use the BoolQ Dataset from Hugging Face\n",
    "2. Use pre-trained model for word embeddings (word2vec, GloVe or fastText)\n",
    "3. Train a 2-layer classifier with ReLU non-linearity\n",
    "\n",
    "In this project I will be using pre-trained embeddings from word2vec and a simple 2-layer neural network to do the reading comprehension task on the BoolQ dataset.\n",
    "I will document every decision made, from preprocessing to model training and evaluation. The goal is to classify each BoolQ question-answer pair as either 'Yes' or 'No'.\n",
    "\n",
    "## TLDR; Here are the key decisions and justifications:\n",
    "- BoolQ Dataset: Provided by Project berief\n",
    "- Task: Classify BoolQ questions as either \"yes\" or \"no\" using pre-trained embeddings and a simple neural network\n",
    "- Pre-trained embeddings: word2vec - Google News 300; for simplicity and already have a bit of experience with it\n",
    "- Model: 2-layer NN with ReLU activation: Provided by Project brief\n",
    "- Tokenizing: Yes, using a subword tokenizer.\n",
    "- Lowercasing: Yes, all text will be lowercased.\n",
    "- Stemming: No, stemming will not be applied.\n",
    "- Lemmatizing: No, lemmatizing is not used initially but could be tried later.\n",
    "- Stopword removal: No, stopwords are not removed to retain key information.\n",
    "- Removal of other words: No, no other word removal is planned.\n",
    "- Format cleaning: No further cleaning required, the dataset is already clean.\n",
    "- Truncation: Yes, input text is truncated to a maximum of 512 tokens.\n",
    "- Feature selection: None, relying on word2vec embeddings directly.\n",
    "- Input format: Tokenized and padded sequences of word2vec embeddings.\n",
    "- Label format: Binary (1 for \"yes\", 0 for \"no\").\n",
    "- train/valid/test splits: 66% train, 8% validation, 26% test.\n",
    "- Padding: Yes, sequences are padded for uniform input length.\n",
    "- Embedding: Pre-trained word2vec embeddings are used for simplicity.\n",
    "- Planned correctness tests: Shape consistency checks, binary label correctness, and validation of truncation and padding.\n",
    "- Hyperparameters:\n",
    "    - Learning Rate: 1e-2 – 1e-5\n",
    "    - Batch Size: 16 - 64 (choosing maximum possible that my GPU can handle)\n",
    "    - Epochs 10 - 50 in 5-/10-step increments\n",
    "    - Hidden size: 64 - 512 \n",
    "    - Early Stopping: Patience of 3 - 10 Epochs of non-improvement (depending on total epoch number)\n",
    "- Evaluation: Accuracy and F1-Score: Accuracy for general performance and F1 to handle class imbalances\n",
    "- Error Analysis: Investigating False Positives and False negatives to understand where the model fails"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc0b9a787988edcb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "Importing necessary libraries:\n",
    "- datasets\n",
    "- gensim\n",
    "- transformers\n",
    "- numpy\n",
    "- torch\n",
    "- wandb\n",
    "- sklearn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7923605f52ff9399"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First up the BoolQ dataset is loaded"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7004488f0ec3eb3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:26.617451Z",
     "start_time": "2024-09-30T16:41:26.565582Z"
    }
   },
   "id": "290a1930d5aa00db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For easy access during experiments I like to define the hyperparameters at the top of my notebooks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5e81ed52db754a8"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Hyperparameters:\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:26.640691Z",
     "start_time": "2024-09-30T16:41:26.568043Z"
    }
   },
   "id": "27891755da01cbdd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the pre-trained embeddings from word2vec"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ac159201e4f8349"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (down-)load word2vec - word2vec-google-news-300"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-09-30T16:41:26.570700Z"
    }
   },
   "id": "ca7cd134842c8958"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "\n",
    "The BoolQ data will be processed in the following way:\n",
    "1.  Tokenizing: the input questions and passages using a subword tokenizer\n",
    "2.  Lowercasing: the text for simplicity and to reduce the total vocabulary size\n",
    "3.  Stemming: No, will not stem the words as to not lose information\n",
    "4.  Lemmatizing: No, will try if it improves performance\n",
    "5.  Stopword removal: No, will not be removed to not lose potentially critical information [research](https://datascience.stackexchange.com/questions/31048/pros-cons-of-stop-word-removal)\n",
    "6.  Removal of other words: No, will not be removing any other words\n",
    "7.  Format cleaning: The dataset is already sufficiently clean, it shouldn't impact performance\n",
    "8.  Truncation: the input text is truncated to a maximum of 512 tokens\n",
    "9.  Feature selection: Not applicable as we focus on raw text as input and leveraging the pre-trained word embeddings no further feature extraction is needed.\n",
    "10. Input format: Will take the form of the tokenized and padded sequences of word embeddings\n",
    "11. Label format: Binary labels \"yes\" or \"no\"\n",
    "12. train/valid/test splits: Prerequisite to project (66/8/26)\n",
    "13. Padding: the sequences is padded to ensure all inputs have the same length in each batch\n",
    "14. Embedding: Using word2vec, solely for simplicity as I already know it.\n",
    "15. Planned correctness tests: Check for shape mismatches between tokenized text and word embeddings. - Ensure that input sequences are properly truncated and padded. - Verify that binary labels are correctly assigned and match the expected outputs.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f45ae072eeb522f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Preprocess text (lowercasing)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80e5c0360f3733c8"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.122238Z",
     "start_time": "2024-09-30T16:41:27.117216Z"
    }
   },
   "id": "33f5bbffdb41ff92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Tokenize with AutoTokenizer from Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4afb45d935e577dc"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# tokenize w/ AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.122472Z",
     "start_time": "2024-09-30T16:41:27.118333Z"
    }
   },
   "id": "f8718b756b58eb0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Truncate or add padding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b668490c2f22c73e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.122554Z",
     "start_time": "2024-09-30T16:41:27.119548Z"
    }
   },
   "id": "da27021cbde658ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. embed tokens using word2vec (word2vec-google-news-300)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4480916ef022ad32"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.124504Z",
     "start_time": "2024-09-30T16:41:27.121496Z"
    }
   },
   "id": "a08858dc075f9bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Create a custom BoolQ dataset class to:\n",
    "    - get the data into a compatible format for the pyTorch dataloader.\n",
    "    - organize question-answer pairs and apply the preprocessing pipeline.\n",
    "    - easily batch, shuffle, and load the data during training."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f406a75fa663ed2f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# class BoolQDataset(dataset):"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.125735Z",
     "start_time": "2024-09-30T16:41:27.124169Z"
    }
   },
   "id": "68b80b754455711f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Dataloaders as required by pyTorch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a911c23aa942989"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.131657Z",
     "start_time": "2024-09-30T16:41:27.125613Z"
    }
   },
   "id": "fdc7fd0fa951faa3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Initialize weights and biases for experiment tracking"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d57c1b1d4d889aac"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.131814Z",
     "start_time": "2024-09-30T16:41:27.127607Z"
    }
   },
   "id": "e4d8b0f2e45c1aed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model\n",
    "\n",
    "The model architecture for this project is already fixed in the project brief as follows:\n",
    "- **Network Architecture:** 2-Layer with ReLu non-linearity.\n",
    "- **Loss / Optimizer:** Loss: CrossEntropyLoss / Optimizer: Adam (potentially trying SGD with or without momentum in experiments)\n",
    "- **Experiments to run**: Mentioned in Training section below\n",
    "- **Number of training runs**: Will depend on number of experiments\n",
    "- **Checkpointing / Early stopping:** 3 - 10 epochs of non-improvement of the validation loss\n",
    "- **Planned correctness tests:** Shape and Dimension consistency tests, Gradient Check, Sanity Check & Prediction Testd"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41588a415c4a9457"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Creating the neural network class:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "372a17c9339ed26b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.131871Z",
     "start_time": "2024-09-30T16:41:27.129126Z"
    }
   },
   "id": "e88677b1ed7c692d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Create instance of model and move it to the GPU"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9aa8093a7ab3628"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.133995Z",
     "start_time": "2024-09-30T16:41:27.131409Z"
    }
   },
   "id": "7faae51ad4eb6f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Loss (nn.CrossEntropyLoss) and optimizer (optim.Adam)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ccdaaae9cb17991"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.134900Z",
     "start_time": "2024-09-30T16:41:27.133054Z"
    }
   },
   "id": "8a9517bd58eaa7cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Training loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35a130a8db2718d5"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.135927Z",
     "start_time": "2024-09-30T16:41:27.134678Z"
    }
   },
   "id": "e70ec39db30393ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Evaluation function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7395aa4d914c29cc"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.142139Z",
     "start_time": "2024-09-30T16:41:27.136636Z"
    }
   },
   "id": "68905d506c269a9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "Train the model with the following different hyperparameters:\n",
    "- Learning rate: 1e-2 – 1e-5\n",
    "- Batch size: 16 - 64\n",
    "- Epochs: 10 - 50\n",
    "- Hidden size: 64 - 512\n",
    "- Early Stopping: Patience of 3 - 10 Epochs of non-improvement\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60e49144e1bbf412"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.142327Z",
     "start_time": "2024-09-30T16:41:27.138188Z"
    }
   },
   "id": "3c59674184ff3416"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n",
    "The model will be evaluated for the key metrics of:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "\n",
    "The results will be averaged using micro averaging because I care about the total number of correct prediction regardless of the class (\"yes\" or \"no\"). \n",
    "\n",
    "Errors will be evaluated by making a confusion matrix and giving me the distribution of ture positives, false positives, true negatives and false negatives. Helping me figure out where the model is making most of it's mistakes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b5ef8c4a2461190"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.172731Z",
     "start_time": "2024-09-30T16:41:27.142651Z"
    }
   },
   "id": "99adb580a3aa62c8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finish the WandB run\n",
    "Closing the WandB run"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84f45c239d144cd8"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.173136Z",
     "start_time": "2024-09-30T16:41:27.143968Z"
    }
   },
   "id": "bffc6238cff90999"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Interpretation\n",
    "\n",
    "To set concrete expectations for my model I take into account a couple of key benchmarks:\n",
    "- **Accuracy:** Given the task of binary classification an accuracy of ~50% can be achieved with random guesses.\n",
    "    - Expecting my model to hit an accuracy of ~60-75%.\n",
    "- **F1 Score:** For this dataset I expect the F1 score to be similar to the accuracy of ~60-75%"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60dffd5636dc69ec"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:41:27.173202Z",
     "start_time": "2024-09-30T16:41:27.145750Z"
    }
   },
   "id": "eea5c07a77e6af43"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
