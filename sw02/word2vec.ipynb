{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "We will use word2vec with gensim to solve word similarity and analogy tasks. Use gensim's [word2vec tutorial](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html) for a reference of the functions we need.\n",
    "\n",
    "First, we download the word embeddings pretrained on the (private) Google News corpus. The embeddings are quite big with 1.7 GB. They will be downloaded to your `<HOME>/gensim-data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------] 1.4% 23.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==------------------------------------------------] 5.1% 84.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====----------------------------------------------] 8.8% 146.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======--------------------------------------------] 12.4% 207.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========------------------------------------------] 16.1% 268.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========-----------------------------------------] 19.8% 329.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========---------------------------------------] 23.5% 391.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============-------------------------------------] 27.3% 453.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============-----------------------------------] 31.1% 516.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================---------------------------------] 34.9% 580.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================-------------------------------] 38.7% 643.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================-----------------------------] 42.5% 706.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================---------------------------] 46.3% 770.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================-------------------------] 50.1% 833.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================------------------------] 53.9% 897.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================----------------------] 57.8% 960.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================--------------------] 61.5% 1022.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================------------------] 65.0% 1080.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================-----------------] 67.7% 1126.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================----------------] 68.7% 1143.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================================---------------] 71.5% 1188.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================--------------] 72.5% 1205.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================================-------------] 75.2% 1250.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================================------------] 76.2% 1266.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================================-----------] 78.9% 1312.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================================-----------] 79.9% 1328.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================---------] 82.7% 1374.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================---------] 83.6% 1390.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================================-------] 86.4% 1436.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================================-------] 87.4% 1452.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================================-----] 90.1% 1498.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================================-----] 91.1% 1515.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================================----] 93.8% 1560.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============================================---] 94.8% 1575.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================================--] 97.5% 1622.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 98.5% 1637.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the vector size, vocabulary size and its first 10 and last 5 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worod #0/3000000 is </s>\n",
      "worod #1/3000000 is in\n",
      "worod #2/3000000 is for\n",
      "worod #3/3000000 is that\n",
      "worod #4/3000000 is is\n",
      "worod #5/3000000 is on\n",
      "worod #6/3000000 is ##\n",
      "worod #7/3000000 is The\n",
      "worod #8/3000000 is with\n",
      "worod #9/3000000 is said\n",
      "worod #2999995/3000000 is RAFFAELE\n",
      "worod #2999996/3000000 is Bim_Skala_Bim\n",
      "worod #2999997/3000000 is Mezze_Cafe\n",
      "worod #2999998/3000000 is pulverizes_boulders\n",
      "worod #2999999/3000000 is snowcapped_Caucasus\n"
     ]
    }
   ],
   "source": [
    "wv.vector_size\n",
    "len(wv)\n",
    "\n",
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"worod #{index}/{len(wv.index_to_key)} is {word}\")\n",
    "for index, word in enumerate(wv.index_to_key[-5:], len(wv)-5):\n",
    "    print(f\"worod #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the vectors for woman, man, queen and king."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = [wv[word] for word in [\"woman\", \"man\", \"queen\", \"king\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute their norms. Are they normalized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.655624, 2.3106172, 3.0283043, 2.9022589]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "norms = [np.linalg.norm(vec) for vec in vecs]\n",
    "print(norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Similarity\n",
    "We will now perform a few operations that use word similarity.\n",
    "\n",
    "Given the pairs below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'democracy'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... compute the word similarity of each pair, once with [sklearn's cosine similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html), and once with gensim's similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'car' and 'minivan': 0.6907036304473877\n",
      "Cosine similarity between 'car' and 'bicycle': 0.5364484190940857\n",
      "Cosine similarity between 'car' and 'airplane': 0.42435580492019653\n",
      "Cosine similarity between 'car' and 'cereal': 0.13924746215343475\n",
      "Cosine similarity between 'car' and 'democracy': 0.07882189750671387\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sk_cosine_similarities = []\n",
    "\n",
    "def cosine_sim(vec1, vec2):\n",
    "    vec1 = vec1.reshape(1, -1)\n",
    "    vec2 = vec2.reshape(1, -1)\n",
    "    return cosine_similarity(vec1, vec2)[0][0]\n",
    "\n",
    "for x, y in pairs:\n",
    "    vec_x = wv[x]\n",
    "    vec_y = wv[y]\n",
    "\n",
    "    similarity_sklearn = cosine_sim(np.array(vec_x), np.array(vec_y))\n",
    "\n",
    "    sk_cosine_similarities.append((x, y, similarity_sklearn))\n",
    "\n",
    "for x, y, sim in cosine_similarities:\n",
    "    print(f\"Cosine similarity between '{x}' and '{y}': {sim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most similar word to all of the words: bike, train, plane, car, bus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bicycle', 0.6886472702026367), ('scooter', 0.6554736495018005), ('buses', 0.6376952528953552), ('van', 0.6202338337898254), ('trolley', 0.6202057600021362)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=['bike', 'train', 'plan', 'car', 'bus'], topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odd one out.** Find the term that doesn't fit the rest of the list: fire, water, land, car, sea, air."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    }
   ],
   "source": [
    "print(wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our word vectors on the WordSim353 dataset. You can get it from `datapath('wordsim353.tsv')` (import `datapath` from `gensim.test.utils`). What's the Pearson correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PearsonRResult(statistic=0.6238773466616107, pvalue=1.7963237724177023e-39),\n",
       " SignificanceResult(statistic=0.6589215888009288, pvalue=2.5346056459149263e-45),\n",
       " 0.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "dataset = datapath('wordsim353.tsv')\n",
    "wv.evaluate_word_pairs(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Analogy\n",
    "We also want to evaluate our word embeddings on the word analogy task. The test set from the original word2vec paper also comes with gensim, and is found in `datapath('questions-words.txt')`. Let's look at the categories that are present in the test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : capital-common-countries\n",
      "507 : capital-world\n",
      "5032 : currency\n",
      "5899 : city-in-state\n",
      "8367 : family\n",
      "8874 : gram1-adjective-to-adverb\n",
      "9867 : gram2-opposite\n",
      "10680 : gram3-comparative\n",
      "12013 : gram4-superlative\n",
      "13136 : gram5-present-participle\n",
      "14193 : gram6-nationality-adjective\n",
      "15793 : gram7-past-tense\n",
      "17354 : gram8-plural\n",
      "18687 : gram9-plural-verbs\n"
     ]
    }
   ],
   "source": [
    "with open(datapath('questions-words.txt')) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if line.startswith(':'):\n",
    "            print(i, line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save us some computation time, we're just going to use the first category, `capital-common-countries`. We store its evaluation examples in a new text file `word-analogies.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[': capital-common-countries\\n', 'Athens Greece Baghdad Iraq\\n', 'Athens Greece Bangkok Thailand\\n', 'Athens Greece Beijing China\\n', 'Athens Greece Berlin Germany\\n', 'Athens Greece Bern Switzerland\\n', 'Athens Greece Cairo Egypt\\n', 'Athens Greece Canberra Australia\\n', 'Athens Greece Hanoi Vietnam\\n', 'Athens Greece Havana Cuba\\n']\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "with open(datapath('questions-words.txt')) as f:\n",
    "    for line in f:\n",
    "        if line.startswith(': capital-world'):\n",
    "            break\n",
    "        lines.append(line)\n",
    "print(lines[:10])\n",
    "with open(datapath('word-analogies.txt'), 'w') as f:\n",
    "    f.writelines(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate our model with gensim's built-in function `evaluate_word_analogies`. Save the results to a variable `analogy_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy_scores = wv.evaluate_word_analogies(datapath('word-analogies.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the accuracy and show an example of a correctly solved analogy, and an incorrectly solved one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8320158102766798\n",
      "Correct: 0.8320158102766798\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {analogy_scores[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Let's visualize our word embeddings in two dimensions. We use PCA to reduce the dimensionality of our 300-dim word vectors to 2. Below is a function `display_scatterplot` that takes a list of words as input and plots them in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def display_scatterplot(model, words): # assumes all words are in the vocabulary\n",
    "    word_vectors = [model[word] for word in words]\n",
    "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x + 0.03, y + 0.03, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of words that could be present in an analogy task. Plot their down-projected embeddings. Can you detect a vector for the relation of your analogy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = ['football', 'grass', 'hockey', 'ice', 'ski', 'snow']\n",
    "display_scatterplot(wv, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun with words\n",
    "Try your own skills in guessing the hidden word by entering words and receiving the cosine similarity on [Semantle](https://semantle.com/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
