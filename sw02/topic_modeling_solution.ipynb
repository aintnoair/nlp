{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53d81604-025d-4fe1-a130-6a978f5ba135",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "In this exercise, we will do topic modeling with gensim. Use the [topics and transformations tutorial](https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html) as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45876ae-0f77-4bf8-8da4-b18618005327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import gensim\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e6efd1",
   "metadata": {},
   "source": [
    "For tokenizing words and stopword removal, download the NLTK punkt tokenizer and stopwords list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf524f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\iamarfur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\iamarfur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee84f40-20bf-47da-b0b4-a0ff28f9b5cd",
   "metadata": {},
   "source": [
    "First, we load the [Lee Background Corpus](https://hekyll.services.adelaide.edu.au/dspace/bitstream/2440/28910/1/hdl_28910.pdf) included with gensim that contains 300 news articles of the Australian Broadcasting Corporation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d72e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "train_file = datapath('lee_background.cor')\n",
    "articles_orig = open(train_file).read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b2e56f",
   "metadata": {},
   "source": [
    "Preprocess the text by lowercasing, removing stopwords, stemming, and removing rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a870af-9f6b-43ea-940f-558e9a21bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stopword list\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords = stopwords | {'\\\"', '\\'', '\\'\\'', '`', '``', '\\'s'}\n",
    "\n",
    "# initialize stemmer\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "def preprocess(article):\n",
    "    # tokenize\n",
    "    article = nltk.word_tokenize(article)\n",
    "\n",
    "    # lowercase all words\n",
    "    article = [word.lower() for word in article]\n",
    "\n",
    "    # remove stopwords\n",
    "    article = [word for word in article if word not in stopwords]\n",
    "\n",
    "    # optional: stem\n",
    "    # article = [stemmer.stem(word) for word in article]\n",
    "    return article\n",
    "\n",
    "articles = [preprocess(article) for article in articles_orig]\n",
    "\n",
    "# create the dictionary and corpus objects that gensim uses for topic modeling\n",
    "dictionary = gensim.corpora.Dictionary(articles)\n",
    "\n",
    "# remove words that occur in less than 2 documents, or more than 50% of documents\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.5)\n",
    "temp = dictionary[0]  # load the dictionary by calling it once\n",
    "corpus_bow = [dictionary.doc2bow(article) for article in articles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ae61a",
   "metadata": {},
   "source": [
    "\n",
    "Now we create a TF-IDF model and transform the corpus into TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab13db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.045163832296308125), (1, 0.049004990699027966), (2, 0.09398031720792203), (3, 0.06797874731615453), (4, 0.08637534553463992), (5, 0.10158528888120417), (6, 0.058872481173046734), (7, 0.045871696227162966), (8, 0.04660732651093343), (9, 0.03476708703034139), (10, 0.09174339245432593), (11, 0.06379342938648586), (12, 0.08097953226203827), (13, 0.08637534553463992), (14, 0.06576958891547403), (15, 0.05748249959948285), (16, 0.07679421433236962), (17, 0.09398031720792203), (18, 0.04197717742438698), (19, 0.06379342938648586), (20, 0.09398031720792203), (21, 0.07679421433236962), (22, 0.08097953226203827), (23, 0.058872481173046734), (24, 0.05497796237027076), (25, 0.05497796237027076), (26, 0.07337456058875615), (27, 0.05497796237027076), (28, 0.08637534553463992), (29, 0.058872481173046734), (30, 0.062005775644911734), (31, 0.08637534553463992), (32, 0.09398031720792203), (33, 0.04737299069698862), (34, 0.07048328454536662), (35, 0.09398031720792203), (36, 0.09398031720792203), (37, 0.07679421433236962), (38, 0.06379342938648586), (39, 0.09398031720792203), (40, 0.05276880396959025), (41, 0.3161468260741569), (42, 0.06576958891547403), (43, 0.06576958891547403), (44, 0.04197717742438698), (45, 0.1860173269347352), (46, 0.08637534553463992), (47, 0.09398031720792203), (48, 0.17275069106927984), (49, 0.15358842866473923), (50, 0.1973087667464221), (51, 0.19138028815945754), (52, 0.06379342938648586), (53, 0.18796063441584407), (54, 0.07679421433236962), (55, 0.05384087678041912), (56, 0.07679421433236962), (57, 0.07679421433236962), (58, 0.08637534553463992), (59, 0.04318767276731996), (60, 0.13595749463230905), (61, 0.07048328454536662), (62, 0.06797874731615453), (63, 0.04318767276731996), (64, 0.08637534553463992), (65, 0.04448171465359908), (66, 0.049877527926200725), (67, 0.07337456058875615), (68, 0.05175471008582299), (69, 0.029876861457627475), (70, 0.043823535964961836), (71, 0.07337456058875615), (72, 0.1663540992526395), (73, 0.048171245973727274), (74, 0.09398031720792203), (75, 0.062005775644911734), (76, 0.04274284161044218), (77, 0.07337456058875615), (78, 0.06037377564287238), (79, 0.18796063441584407), (80, 0.09398031720792203), (81, 0.06379342938648586), (82, 0.23038264299710884), (83, 0.05618845771320373), (84, 0.08097953226203827), (85, 0.06379342938648586), (86, 0.07048328454536662), (87, 0.05384087678041912), (88, 0.06797874731615453), (89, 0.14342796675805272), (90, 0.07679421433236962), (91, 0.10995592474054151), (92, 0.06379342938648586), (93, 0.03976801902370649), (94, 0.0360042057531442), (95, 0.06797874731615453), (96, 0.07679421433236962), (97, 0.058872481173046734), (98, 0.11930405707111948), (99, 0.07679421433236962), (100, 0.030502124955654616), (101, 0.1860173269347352), (102, 0.05618845771320373), (103, 0.058872481173046734), (104, 0.08097953226203827), (105, 0.17529414385984735), (106, 0.11237691542640746), (107, 0.045871696227162966), (108, 0.08097953226203827), (109, 0.06037377564287238), (110, 0.03398546693692743)]\n"
     ]
    }
   ],
   "source": [
    "model_tfidf = gensim.models.TfidfModel(corpus_bow)\n",
    "corpus_tfidf = model_tfidf[corpus_bow]\n",
    "print(corpus_tfidf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24df8cb",
   "metadata": {},
   "source": [
    "Now we train an [LDA model](https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html) with 10 topics on the TF-IDF corpus. Save it to a variable `model_lda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ded6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lda = gensim.models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91845654",
   "metadata": {},
   "source": [
    "Let's inspect the first 5 topics of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca3a357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6,\n",
       "  '0.002*\"palestinian\" + 0.002*\"arafat\" + 0.002*\"israeli\" + 0.001*\"hospital\" + 0.001*\"army\" + 0.001*\"hih\" + 0.001*\"use\" + 0.001*\"assa\" + 0.001*\"abloy\" + 0.001*\"new\"'),\n",
       " (9,\n",
       "  '0.003*\"palestinian\" + 0.002*\"israeli\" + 0.002*\"arafat\" + 0.002*\"zinni\" + 0.002*\"israel\" + 0.002*\"fire\" + 0.001*\"south\" + 0.001*\"weather\" + 0.001*\"mr\" + 0.001*\"test\"'),\n",
       " (5,\n",
       "  '0.003*\"palestinian\" + 0.002*\"israeli\" + 0.002*\"gaza\" + 0.002*\"sharon\" + 0.002*\"radio\" + 0.002*\"strip\" + 0.001*\"hill\" + 0.001*\"markets\" + 0.001*\"arafat\" + 0.001*\"zimbabwe\"'),\n",
       " (7,\n",
       "  '0.002*\"qantas\" + 0.002*\"palestinian\" + 0.002*\"mr\" + 0.002*\"us\" + 0.001*\"taliban\" + 0.001*\"suicide\" + 0.001*\"workers\" + 0.001*\"afghanistan\" + 0.001*\"australian\" + 0.001*\"bin\"'),\n",
       " (2,\n",
       "  '0.002*\"taliban\" + 0.002*\"afghanistan\" + 0.002*\"government\" + 0.002*\"williams\" + 0.002*\"australian\" + 0.002*\"bin\" + 0.002*\"fire\" + 0.002*\"laden\" + 0.002*\"australia\" + 0.002*\"detainees\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lda.print_topics(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ce453",
   "metadata": {},
   "source": [
    "We see the 5 topics with the highest importance. For each topic, the 10 most important words are shown, together with their coefficient of \"alignment\" to the topic.\n",
    "\n",
    "## Document Similarity\n",
    "We now use our LDA model to compare the similarity of new documents (*queries*) to documents in our collection.\n",
    "\n",
    "First, create an index of the news articles in our corpus. Use the `MatrixSimilarity` transformation as described in gensim's [similarity queries tutorial](https://radimrehurek.com/gensim/auto_examples/core/run_similarity_queries.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb44cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(model_lda[corpus_tfidf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b2c1f",
   "metadata": {},
   "source": [
    "Now, write a function that takes a query string as input and returns the LDA representation for it. Make sure to apply the same preprocessing as we did to the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dabf9dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_vector(text):\n",
    "    text = preprocess(text)\n",
    "    bow = dictionary.doc2bow(text)\n",
    "    tfidf = model_tfidf[bow]\n",
    "    lda = model_lda[tfidf]\n",
    "    return lda\n",
    "\n",
    "lda_vector = get_lda_vector('A new bill sparked massive protests in Israel, as it would massively limit the powers of the judiciary.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77753be",
   "metadata": {},
   "source": [
    "Print the top 5 most similar documents, together with their similarities, using your index created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7696f2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99852127 New statistics released by the Cancer Council reveal some alarming trends about lung cancer. The report reveals lung cancer now rivals breast cancer as the leading cause of cancer death among women. The statistics, covering the past three decades, also show high numbers of lung cancer cases and deaths in poorer areas such as some parts of Sydney and far western New South Wales. The Cancer Council's chief executive officer, Andrew Penman, says another trend is in the type of lung cancer which is believed to be caused by changes in the design of cigarettes. \"Modern cigarettes are particularly dangerous to the peripheral airways and they're causing lung cancers deeper in the lungs than traditional cigarettes say 40 years ago,\" he said. About 2,200 people die from lung cancer in New South Wales each year. \n",
      "0.9979083 A pay freeze dispute involving Qantas and its maintenance workers will remain unresolved over the Christmas period. The parties failed to reach agreement during talks in the Industrial Relations Commission in Melbourne this morning. More than 2,000 employees have imposed work bans and stoppages in their campaign for a 3 per cent pay rise. Both the union and Qantas say there will not be flight disruptions. \n",
      "0.9978335 Joseph Gutnick, the saviour and former president of the Melbourne Football Club, has failed in his bid to be re-elected as president, after stepping down earlier this year. He was also dumped from the board. Gabriel Szondy and his Team Vision ticket comprehensively beat Mr Gutnick's Melbourne First ticket, in an election which saw 75 per cent of the club's more than 16,000 members vote. Mr Szondy says he is pleased it was such a decisive victory. \"We're very happy that the members have voted so overwhelmingly in support of the ticket and it hasn't been cherry-picked,\" he said. He attributed the victory to both the presence of former Demon's great Robert Flower on his ticket and Mr Gutnick's ill-timed attempt to settle the presidency issue mid-season. Arriving at the club's annual general meeting last night, Mr Gutnick said regardless of the outcome, he expected the result to unite the club. \"It shouldn't divide the club, we should drop all our differences and work together.\" \n",
      "0.99783224 South Africa is considering playing left arm spinner Nicky Boje in this week's third Test against Australia in Sydney. Boje was forced to withdraw from the South African squad before the start of the tour due to injury. South African captain Shaun Pollock says he hopes Boje arrives in time to prepare for the Test. \"Nicky Boje might be out in time,\" he said. \"As soon as he was fit and ready he was going to come over but we'll be picking the best possible eleven for the Sydney Test.\" \n",
      "0.9977312 Australian cricket selectors have made just one change to the squad that beat South Africa in the opening Test for the second Test beginning in Melbourne on Boxing Day. As predicted, Queensland pace bowler Andy Bichel replaces spin bowler Stuart MacGill, who was 12th man for the Adelaide Test. MacGill took five wickets for New South Wales on day one of the tour match against South Africa at the SCG yesterday, but it was not enough to sway selectors. \n"
     ]
    }
   ],
   "source": [
    "document_similarities = index[lda_vector]\n",
    "for doc_idx, doc_similarity in sorted(enumerate(document_similarities), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(doc_similarity, articles_orig[doc_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e05dba",
   "metadata": {},
   "source": [
    "Run your code again, now training an LDA model with 100 topics. Do you see a qualitative difference in the top-5 most similar documents?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
