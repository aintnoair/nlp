{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers for BoolQ reading comprehension\n",
    "*All changes and additions compared to Stage 1 are marked in <span style=\"color: orange;\">orange</span>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "My sources for this project are linked in the respecting sections of the notebook. I used AI tools such as ChatGPT to correct my writing and grammar in stage 1 of this project and plan on using it for debugging during stage 2."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style=\"color: orange;\">TLDR - Executive summary</span>\n",
    "### **Topic:**\n",
    "Develop and train a Transformer-based model end to end for binary question answering on the BoolQ dataset from Huggin Face.\n",
    "\n",
    "### **Data:**\n",
    "The dataset is for reading comprehension and question answering tasks. It consists of questions, passages and the corresponding yes/no answers, with seperate training and test splits. Splitting the last 1000 entries of the training split to use as a validation split in this project.\n",
    "\n",
    "### **Methods:**\n",
    "The project involves preprocessing the data using the AutoTokenizer with the pre-trained \"bert-base-cased\" model. Then transforming the token IDs to word embeddings using the nn.Embedding layer. Using projection layer in between we reach the transformerEncoder with six layers followed by the mean pooling layer for dimensionality reduction into the 2-layer classifier from which we finally receive the binary output.\n",
    "\n",
    "### **Model:**\n",
    "The model is based on a PyTorch implementation of a Transformer Encoder, structured as follows:\n",
    "- Embedding Layer: nn.Embedding layer to map tokens to embeddings.\n",
    "- Positional Embedding Layer: Adds positional information to embeddings.\n",
    "- Linear Projection Layer: Projects from embedding dimension to transformer hidden dimension.\n",
    "- Transformer Encoder: A 6-layer transformer encoder block.\n",
    "- Pooling Layer: Mean pooling for dimensionality reduction.\n",
    "- Classifier: A 2-layer classifier with ReLU non-linearity.\n",
    "- Loss Function: Cross-Entropy Loss.\n",
    "\n",
    "### **Experiments:**\n",
    "Link to WandB: [Weights and Biases]() <br>\n",
    "17 manual experiments were conducted, exploring combinations of transformer (from 128 to 1024) and classifier hidden dimensions (from 64 to 512) as well as embedding dimensions (from 128 to 512) as well as further adjustments mentioned in more detail in the model section of the notebook.\n",
    "\n",
    "### **Results:**\n",
    "Key findings:\n",
    "- Adding 100 warmup steps at a batch size of 64 improved performance compared to no warmup.\n",
    "- A dropout rate of 0.2 was introduced to reduce overfitting on the training set.\n",
    "- After facing some issues with optuna for automatic hyperparameter tuning, manual tuning resulted in a model barely outperforming the majority baseline test accuracy of 62.17% with a test accuracy of **63.70%**.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**Importing Python Packages**\n",
    "Making sure the notebook is reproducible and runs without error, I will install the necessary libraries in a pip cell below.\n",
    "\n",
    "**Data Loading and Split**\n",
    "The data consists of the questions, a passage and the answer. In total there are 12'697 entries in the dataset. Splitting them according to the lecture slides into train (8427), validation (1000) and test (3270).\n",
    "\n",
    "**Seeding for Reproducibility**\n",
    "Setting the random Seed to 42 for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T20:18:31.436168Z",
     "start_time": "2024-11-11T20:18:28.900885Z"
    }
   },
   "source": [
    "# TODO: make the pip install for used libraries and packages !!!\n",
    "%pip install -q wandb datasets torch transformers pytorch_lightning torchmetrics matplotlib seaborn scikit-learn "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:18:34.170413Z",
     "start_time": "2024-11-11T20:18:34.165499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from pathlib import Path\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryConfusionMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:18:35.571377Z",
     "start_time": "2024-11-11T20:18:35.536878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "pl.seed_everything(42, workers=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:18:36.804915Z",
     "start_time": "2024-11-11T20:18:36.791054Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:18:37.601109Z",
     "start_time": "2024-11-11T20:18:37.597358Z"
    }
   },
   "cell_type": "code",
   "source": "BATCH_SIZE = 64",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading the dataset based on lecture slides\n",
    "train_data = load_dataset('google/boolq', split='train[:-1000]')\n",
    "validation_data = load_dataset('google/boolq', split='train[-1000:]')\n",
    "test_data = load_dataset('google/boolq', split='validation')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:18:45.004870Z",
     "start_time": "2024-11-11T20:18:37.958097Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "test_question = train_data[5]['question']\n",
    "test_passage = train_data[5]['passage']\n",
    "print(train_data[5])\n",
    "print(f\"Number of training samples: {len(train_data)}\")\n",
    "print(f\"Number of validation samples: {len(validation_data)}\")\n",
    "print(f\"Number of validation samples: {len(test_data)}\")\n",
    "\n",
    "train_yes_count = sum(1 for label in train_data['answer'] if label == 1)\n",
    "train_no_count = sum(1 for label in train_data['answer'] if label == 0)\n",
    "train_total = train_yes_count + train_no_count\n",
    "\n",
    "validation_yes_count = sum(1 for label in validation_data['answer'] if label == 1)\n",
    "validation_no_count = sum(1 for label in validation_data['answer'] if label == 0)\n",
    "validation_total = validation_yes_count + validation_no_count\n",
    "\n",
    "test_yes_count = sum(1 for label in test_data['answer'] if label == 1)\n",
    "test_no_count = sum(1 for label in test_data['answer'] if label == 0)\n",
    "test_total = test_yes_count + test_no_count\n",
    "\n",
    "print(f\"Train set (yes/no) Ratio: {round(train_yes_count / train_no_count, 2)}, Percent Yes: {round(train_yes_count / train_total * 100, 2)}%\")\n",
    "\n",
    "print(f\"Validation set (yes/no) Ratio: {round(validation_yes_count / validation_no_count, 2)}, Percent Yes: {round(validation_yes_count / validation_total * 100, 2)}%\")\n",
    "\n",
    "print(f\"Test set (yes/no) Ratio: {round(test_yes_count / test_no_count, 2)}, Percent Yes: {round(test_yes_count / test_total * 100, 2)}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:18:45.027954Z",
     "start_time": "2024-11-11T20:18:45.007867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'can you use oyster card at epsom station', 'answer': False, 'passage': \"Epsom railway station serves the town of Epsom in Surrey. It is located off Waterloo Road and is less than two minutes' walk from the High Street. It is not in the London Oyster card zone unlike Epsom Downs or Tattenham Corner stations. The station building was replaced in 2012/2013 with a new building with apartments above the station (see end of article).\"}\n",
      "Number of training samples: 8427\n",
      "Number of validation samples: 1000\n",
      "Number of validation samples: 3270\n",
      "Train set (yes/no) Ratio: 1.68, Percent Yes: 62.64%\n",
      "Validation set (yes/no) Ratio: 1.47, Percent Yes: 59.5%\n",
      "Test set (yes/no) Ratio: 1.64, Percent Yes: 62.17%\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Tokenizer\n",
    "In past projects I always did some sort of manual preprocessing of the data. In this project I deliberately refrain from any manual preprocessing and will let the built-in features of the AutoTokenizer with the from_pretrained(\"bert-base-cased\") model handle the following steps for me:\n",
    "- Whitespace and Special Character removal (e.g. emojis or phonetic pronunciations)\n",
    "- Case Sensitivity\n",
    "- Padding and Truncation (pad automatically, truncate to max: 512 tokens - amount of pretrained position embeddings)\n",
    "\n",
    "I only now found out about this from the Hugging Face Transformer [Preprocessing Data Documentation](https://huggingface.co/transformers/v3.0.2/preprocessing.html).\n",
    "\n",
    "### Lowercase / Case Sensitivity\n",
    "From my feedback I will now keep case sensitivity instead of lower-casing all text. Example of case sensitivity: the word \"US\" would become \"us\" and could thus change the meaning of a sentence drastically. <br>\n",
    "*Source*: Feedback from Project 2 (LSTM)\n",
    "\n",
    "### Padding / Truncation\n",
    "I rely on the built-in padding and truncation functions of the AutoTokenizer from Hugging Face to manage sequence lengths efficiently:\n",
    "- Questions are limited to a maximum of 21 tokens, based on the length of the longest question in the dataset.\n",
    "- Passages are padded to a maximum of 488 tokens, ensuring that when the question (21 tokens), start token, end token, and separator token are included, the total length remains within the 512-token limit supported by the Transformer’s positional embeddings.\n",
    "\n",
    "### Stemming / Lemmatization / Stopword removal\n",
    "From a past lecture I took away that stemming or lemmatization is not the right choice for a reading comprehension task. It removes valuable meaning\n",
    "No stemming or lemmatization will be done in my preprocessing as to keep the most amount of information possible in my sequences. Stopwords will also not be removed for the same reason.\n",
    "\n",
    "### Embedding Layer\n",
    "In this project, the embedding layer is implemented using PyTorch's nn.Embedding class. The embeddings are trained end-to-end alongside the rest of the model, allowing them to adapt to the specific nuances of the BoolQ dataset.\n",
    "- **Vocabulary Size**: Determined by the tokenizer\n",
    "- **Embedding Dimension**: Set to 300 as this is widely used by large pretrained embedding models like fastText or word2vec.\n",
    "- **Training**: Initialized randomly and updated during training through backpropagation.\n",
    "\n",
    "### Absolute Position Embeddings\n",
    "Since the nn.TransformerEncoder does not by default have positional embeddings I will be implementing them through absolute position embeddings. Choosing the embeddings over the encoding because it is more widely used in practice.\n",
    "Adding the learned absolute positional embeddings to the word embeddings before feeding the input into the transformer model. The position embeddings are initialized randomly and are trained with the model through backpropagation.\n",
    "*Source*: Lecutre on positional encodings\n",
    "\n",
    "### Input / Output / Label format\n",
    "Each data point in the dataset is made up of a questions, passage and the respective binary label. The preprocessing steps transform these into the following formats for my model inputs:\n",
    "- Embedding Layer:\n",
    "    - *input*: Tensor of (batch_size, sequence_length) containing token IDs.\n",
    "    - *output*: Tensor for (batch_size, sequence_length, embedding_dim) with each token ID mapped to a dense vector of size embedding_dim.\n",
    "\n",
    "- 6-Layer Transformer Encoder:\n",
    "    - *input*: The embeddings with shape (batch_size, sequence_length, embedding_dim).\n",
    "    - *output*: A Tensor of shape (batch_size, sequence_length, embedding_dim).\n",
    "\n",
    "- Pooling Layer:\n",
    "    - *input*: The output of the last transformer layer, with shape (batch_size, sequence_length, embedding_dim)\n",
    "    - *output*: A Tensor of shape (batch_size, embedding_dim), representing the aggregated sequence information.\n",
    "\n",
    "- 2-Layer Classifier:\n",
    "    - *input*: The pooled output, with shape (batch_size, embedding_dim)\n",
    "    - *output*: A tensor of shape (batch_size, hidden_dim) for the first layer and shape (batch_size, num_classes) for the final layer.\n",
    "\n",
    "- Label format:\n",
    "    - The labels will be encoded as boolean values, enabling the model to predict either 0 or 1 (False/True)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T20:18:46.143073Z",
     "start_time": "2024-11-11T20:18:45.045025Z"
    }
   },
   "source": [
    "# initialize tokenizer with bert-base-cased model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "\n",
    "\n",
    "def get_max_question_len(dataset):\n",
    "    max_len = 0\n",
    "    for item in dataset:\n",
    "        question = item['question']\n",
    "        tokenized_question = tokenizer.encode(question)\n",
    "        max_len = max(max_len, len(tokenized_question))\n",
    "    return max_len\n",
    "\n",
    "max_question_len = get_max_question_len(train_data)\n",
    "print(max_question_len) # max len of BPE tokenized question (including the CLS and SEP tokens) \n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_batch(batch):\n",
    "    questions = batch['question']\n",
    "    passages = batch['passage']\n",
    "    \n",
    "    encodings = tokenizer(\n",
    "        questions,\n",
    "        passages,\n",
    "        max_length=512,  # Combined max length within Transformer limit\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    return {'input_ids': encodings['input_ids'], 'labels': torch.tensor(batch['answer'])}  # output of input_ids and labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:18:46.159074Z",
     "start_time": "2024-11-11T20:18:46.155073Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# Tokenize the datasets\n",
    "train_data = train_data.map(tokenize_batch, batched=True).with_format(\"torch\", device=DEVICE)\n",
    "validation_data = validation_data.map(tokenize_batch, batched=True).with_format(\"torch\", device=DEVICE)\n",
    "test_data = test_data.map(tokenize_batch, batched=True).with_format(\"torch\", device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:18:46.195299Z",
     "start_time": "2024-11-11T20:18:46.170380Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# Define collate function for dynamic padding in DataLoader\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(item['input_ids']) for item in batch]\n",
    "    labels = torch.tensor([item['labels'] for item in batch])\n",
    "    \n",
    "    # Pad to the longest sequence in the batch\n",
    "    input_ids = nn.utils.rnn.pad_sequence(input_ids, batch_first=True)\n",
    "    return {'input_ids': input_ids, 'labels': labels}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:18:46.209070Z",
     "start_time": "2024-11-11T20:18:46.205066Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:18:46.221258Z",
     "start_time": "2024-11-11T20:18:46.218856Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "### Architecture\n",
    "- **Input Layer**:\n",
    "    - The input to my model is the nn.Embedding layer that will be trained on the dataset with the network.\n",
    "    - Each input sequence consists of a concatenated question and passage with a [SEP] token between them, marking the boundary. The separator token allows the model to distinguish between the two segments.\n",
    "    - The resulting shape of the input tensor after embedding is (batch_size, sequence_length, embedding_dim).\n",
    "    - <span style=\"color: orange;\">Adding a projection layer to reach the expected input dimension of the transformer model of: (batch_size, sequence_length, transformer_hidden_dim) This proved easier to implement than adjusting the first transformer layer.</span>\n",
    "- **6-Layer Transformer Encoder**:\n",
    "    - Using the PyTorch implementation of the Transformer Encoder. The input to this model will be the output of the embedding layer with shape (batch_size, sequence_length, <span style=\"color: orange;\">transformer_hidden_dim</span>). Using six layers to learn contextual representations of the concatenated questino-passage sequence.\n",
    "- **Pooling Layer**:\n",
    "    - Apply *mean pooling* across the sequence length to reducing the output from (batch_size, sequence_length, embedding_dim) to (batch_size, embedding_dim). This provides a fixed-size single vector that summarizes the entire sequence for the classifier which provides the advantage of efficient memory use in training with varying sequence lengths and a fixed-sized input for my classifier.\n",
    "- **2-Layer Classifier with ReLU**\n",
    "    - I will implement a two-layer classifier network as defined in the project assignment. The first layer will take the output from the pooling layer of size (batch_size, embedding_dim) as its input and provide an output shape of (batch_size, hidden_dim). Using a ReLU for non-linearity. The second layer has output dimensions of (batch_size, num_classes) with num_classes=2. The output layer will use a softmax as the activation function as it is preferable over a sigmoid function for binary classification.\n",
    "\n",
    "### Loss and Optimizer\n",
    "For this binary classification task I'm using Binary Cross-Entropy Loss. BCE is widely used in binary classification problems, as it provides a probabilistic interpretation of the model's outputs, making it convenient for distinguishing between two classes. <br>\n",
    "*Source*: [Binary Cross-Entropy/Log Loss for Binary Classification](https://www.geeksforgeeks.org/binary-cross-entropy-log-loss-for-binary-classification/)\n",
    "\n",
    "For my optimizer I choose the Adam Optimizer for its adaptive learning rates and efficient handling of sparse gradients. It is well suited for deep learning tasks, provides fast convergence and has worked well in prior projects. <br>\n",
    "*Source*: [Introduction to the Adam Optimizer](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n",
    "\n",
    "### Experiments\n",
    "*Batch Size*: I will start with a batch_size of 16 and increase it to the maximum my hardware can handle then leaving it fixed as it is not a hyperparameter. <span style=\"color: orange;\">Finally settling on a batch size of 64</span>\n",
    "\n",
    "To tune my models' hyperparameters I will be experimenting with the following ranges:\n",
    "- Learning Rate: [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "- Embedding Dimension: [128, 256, 300]\n",
    "- Hidden Dimension for Classifier: [64, 128, 256]\n",
    "- <span style=\"color: orange;\">Hidden Dimension for Transformer: [128, 1024]</span>\n",
    "- Number of Attention Heads: [4, 8, 12, 16]\n",
    "- Dropout Rate: [0.1, 0.2, 0.3]\n",
    "- Weight Decay: [1e-4, 1e-5, 1e-6]\n",
    "- <span style=\"color: orange;\">Warmup Steps: [0, 500]</span>\n",
    "\n",
    "### Training\n",
    "I do not expect any run to take longer than 25 epochs. Thus limiting the maximum number of epochs to 25 and implement the early stopping criteria like in past projects. <br>\n",
    "<span style=\"color: orange;\"> After some experimenting, I extended the maximum number of epochs to 60 because the model was struggling to learn anything before epoch 25.</span>\n",
    "\n",
    "### Checkpointing and Early Stopping\n",
    "**Checkpointing**: I will implement checkpointing to save the model with the best validation accuracy. Criteria for this will be the maximum validation accuracy.\n",
    "\n",
    "**Early Stopping**: Early stopping the run if the validation loss does not decrease within 15 epochs.\n",
    "\n",
    "### Planned Correctness Tests\n",
    "- Testing input shape to ensure the model receives a valid input format\n",
    "- Testing output shape to verify the model produces the expected output shape\n",
    "- Visually check the loss is decreasing while training\n",
    "- Visually check the output for overfitting\n",
    "- Visually check predictions using a confusion matrix\n",
    "- Ensure reproducibility by setting the random seed.\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "validation_loader = DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:19:03.570239Z",
     "start_time": "2024-11-11T20:19:03.566172Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T20:19:04.276294Z",
     "start_time": "2024-11-11T20:19:04.260474Z"
    }
   },
   "source": [
    "class TransformerClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size,\n",
    "            embedding_dim,\n",
    "            num_heads,\n",
    "            transformer_hidden_dim,\n",
    "            classifier_hidden_dim,\n",
    "            dropout_rate=0.0,\n",
    "            learning_rate=1e-4,\n",
    "            warmup_steps=0,\n",
    "            weight_decay=0.0,\n",
    "            num_layers=6,\n",
    "            num_classes=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Embedding Layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Positional Embedding layer\n",
    "        self.position_embedding = nn.Embedding(512, embedding_dim)\n",
    "        \n",
    "        # Linear layer to project from embedding_dim to transformer_hidden_dim (input dim of Transformer)\n",
    "        self.input_projection = nn.Linear(embedding_dim, transformer_hidden_dim)\n",
    "        \n",
    "        # Transformer encoder with transformer_hidden_dim as input dimension\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=transformer_hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=transformer_hidden_dim * 2,\n",
    "            dropout=dropout_rate,\n",
    "            activation=\"relu\"\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Pooling layer (mean pooling)\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Classifier: 2-layer MLP with dropout\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(transformer_hidden_dim, classifier_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(classifier_hidden_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Accuracy metric\n",
    "        self.train_accuracy = BinaryAccuracy()\n",
    "        self.val_accuracy = BinaryAccuracy()\n",
    "        self.test_accuracy = BinaryAccuracy()\n",
    "        self.test_confusion_matrix = BinaryConfusionMatrix()\n",
    "        \n",
    "        # Storage for predictions and labels\n",
    "        self.test_preds = []\n",
    "        self.test_labels = []\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        positions = torch.arange(input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
    "        pos_embeddings = self.position_embedding(positions)\n",
    "        embedded = embedded + pos_embeddings\n",
    "        \n",
    "        projected = self.input_projection(embedded)\n",
    "        projected = projected.permute(1, 0, 2)\n",
    "        encoded = self.transformer_encoder(projected)\n",
    "        encoded = encoded.permute(1, 0, 2)\n",
    "        \n",
    "        pooled = self.pooling(encoded.transpose(1, 2)).squeeze(-1)\n",
    "        \n",
    "        logits = self.classifier(pooled)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids'].to(self.device)\n",
    "        labels = batch['labels'].long().to(self.device)\n",
    "        \n",
    "        outputs = self(input_ids)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        # Log accuracy and loss\n",
    "        acc = self.train_accuracy(preds, labels)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_accuracy', acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids'].to(self.device)\n",
    "        labels = batch['labels'].long().to(self.device)\n",
    "        \n",
    "        outputs = self(input_ids)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        # Log accuracy and loss\n",
    "        acc = self.val_accuracy(preds, labels)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_accuracy', acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids'].to(self.device)\n",
    "        labels = batch['labels'].long().to(self.device)\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = self(input_ids)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        # Update accuracy and save predictions and labels for confusion matrix\n",
    "        accuracy = self.test_accuracy(preds, labels)\n",
    "        self.test_preds.extend(preds.cpu().numpy())\n",
    "        self.test_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Log test loss and accuracy\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_accuracy\", accuracy, prog_bar=True)\n",
    "        \n",
    "        return {\"test_loss\": loss, \"test_accuracy\": accuracy}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Calculate and plot the confusion matrix\n",
    "        cm = confusion_matrix(self.test_labels, self.test_preds)\n",
    "        self.plot_confusion_matrix(cm)\n",
    "        \n",
    "        # Clear stored predictions and labels after logging\n",
    "        self.test_preds.clear()\n",
    "        self.test_labels.clear()\n",
    "\n",
    "    def plot_confusion_matrix(self, cm):\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=ax)\n",
    "        ax.set_xlabel(\"Predicted labels\")\n",
    "        ax.set_ylabel(\"True labels\")\n",
    "        ax.set_title(\"Confusion Matrix\")\n",
    "        \n",
    "        # Log the plot to WandB\n",
    "        wandb.log({\"confusion_matrix\": wandb.Image(fig)})\n",
    "        plt.close(fig)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "\n",
    "        def lr_lambda(current_step):\n",
    "            if current_step < self.hparams.warmup_steps:\n",
    "                lr = float(current_step) / float(max(1, self.hparams.warmup_steps))\n",
    "                return lr\n",
    "            return 1.0\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': LambdaLR(optimizer, lr_lambda=lr_lambda),\n",
    "            'interval': 'step',\n",
    "            'name': 'learning_rate'\n",
    "        }\n",
    "        \n",
    "        return [optimizer], [scheduler]"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "BATCH_S = 32\n",
    "SEQ_LEN = 512\n",
    "DIM = 300\n",
    "\n",
    "\n",
    "model = TransformerClassifier(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=DIM,\n",
    "    num_heads=8,\n",
    "    transformer_hidden_dim=256,\n",
    "    classifier_hidden_dim=64,\n",
    ").to(DEVICE)\n",
    "\n",
    "x = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, SEQ_LEN)).to(DEVICE)\n",
    "\n",
    "# Run the forward pass and check the output shape\n",
    "assert model.forward(x).shape == torch.Size([BATCH_SIZE, 2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:19:05.820620Z",
     "start_time": "2024-11-11T20:19:05.359184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pascal\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "def test_input_shapes(dataloader, model, batch_size):\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids']  # Shape: (batch_size, sequence_length)\n",
    "        \n",
    "        # Check the batch size\n",
    "        assert input_ids.shape[0] == batch_size, f\"Expected batch size {batch_size}, got {input_ids.shape[0]}\"\n",
    "        \n",
    "        # Pass the input through the model\n",
    "        logits = model(input_ids)\n",
    "        \n",
    "        # Check that logits have the expected shape (batch_size, num_classes)\n",
    "        assert logits.shape[0] == batch_size, f\"Expected logits batch size {batch_size}, got {logits.shape[0]}\"\n",
    "        assert logits.shape[1] == model.classifier[-1].out_features, f\"Expected {model.classifier[-1].out_features} output classes, got {logits.shape[1]}\"\n",
    "        \n",
    "        print(f\"Batch passed with input_ids shape {input_ids.shape} and logits shape {logits.shape}\")\n",
    "        break  # Test the first batch only to verify shapes\n",
    "\n",
    "# Assuming `model` is an instance of TransformerClassifier\n",
    "test_input_shapes(train_loader, model, BATCH_SIZE)\n",
    "test_input_shapes(validation_loader, model, BATCH_SIZE)\n",
    "test_input_shapes(test_loader, model, BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:19:06.790043Z",
     "start_time": "2024-11-11T20:19:06.690009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch passed with input_ids shape torch.Size([64, 512]) and logits shape torch.Size([64, 2])\n",
      "Batch passed with input_ids shape torch.Size([64, 512]) and logits shape torch.Size([64, 2])\n",
      "Batch passed with input_ids shape torch.Size([64, 512]) and logits shape torch.Size([64, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pascal\\AppData\\Local\\Temp\\ipykernel_23712\\1889658370.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = [torch.tensor(item['input_ids']) for item in batch]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# Configuration of my best performing model\n",
    "CONFIG = {\n",
    "    \"embedding_dim\": 256,\n",
    "    \"num_heads\": 8,\n",
    "    \"transformer_hidden_dim\": 512,\n",
    "    \"classifier_hidden_dim\": 128,\n",
    "    \"dropout_rate\": 0.2,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"warmup_steps\": 100,\n",
    "    \"weight_decay\": 1e-4,\n",
    "\n",
    "    \"patience\": 60,\n",
    "    \"epochs\": 60,\n",
    "    \n",
    "    \"num_classes\": 2,\n",
    "    \"vocab_size\": VOCAB_SIZE,\n",
    "    \"num_layers\": 6\n",
    "}\n",
    "\n",
    "# Initialize model with config\n",
    "TransformerModel = TransformerClassifier(\n",
    "    vocab_size=CONFIG[\"vocab_size\"],\n",
    "    embedding_dim=CONFIG[\"embedding_dim\"],\n",
    "    num_heads=CONFIG[\"num_heads\"],\n",
    "    transformer_hidden_dim=CONFIG[\"transformer_hidden_dim\"],\n",
    "    classifier_hidden_dim=CONFIG[\"classifier_hidden_dim\"],\n",
    "    num_layers=CONFIG[\"num_layers\"],\n",
    "    num_classes=CONFIG[\"num_classes\"],\n",
    "    dropout_rate=CONFIG[\"dropout_rate\"],\n",
    "    learning_rate=CONFIG[\"learning_rate\"],\n",
    "    warmup_steps=CONFIG[\"warmup_steps\"],\n",
    "    weight_decay=CONFIG[\"weight_decay\"],\n",
    ")\n",
    "\n",
    "run_name = (\n",
    "    f\"emb_dim_{CONFIG['embedding_dim']}-\"\n",
    "    f\"n_heads_{CONFIG['num_heads']}-\"\n",
    "    f\"trans_h_dim_{CONFIG['transformer_hidden_dim']}-\"\n",
    "    f\"class_h_dim_{CONFIG['classifier_hidden_dim']}-\"\n",
    "    f\"dropout_{CONFIG['dropout_rate']}-\"\n",
    "    f\"lr_{CONFIG['learning_rate']}-\"\n",
    "    f\"warmup_{CONFIG['warmup_steps']}-\"\n",
    "    f\"w_decay_{CONFIG['weight_decay']}\"\n",
    ")\n",
    "\n",
    "print(\"Run Name:\", run_name)\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project='nlp_p3_transformer',\n",
    "    name=run_name,\n",
    "    group=\"manual_runs\"\n",
    ")\n",
    "\n",
    "for key, value in CONFIG.items():\n",
    "    wandb_logger.experiment.config[key] = str(value)\n",
    "\n",
    "wandb_logger.log_hyperparams(TransformerModel.hparams)\n",
    "\n",
    "# Model Checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_accuracy\",            # Monitor validation accuracy\n",
    "    dirpath=\"checkpoints/\",\n",
    "    filename=run_name,\n",
    "    save_top_k=1,\n",
    "    mode=\"max\",                        # Save model with the highest validation accuracy\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Early Stopping callback\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",            # Monitor validation accuracy for early stopping\n",
    "    patience=CONFIG['patience'],\n",
    "    mode=\"max\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Initialize the Trainer with these callbacks\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=CONFIG['epochs'],\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    logger=wandb_logger,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.fit(TransformerModel, train_loader, validation_loader)\n",
    "\n",
    "# Finish the wandb run\n",
    "wandb.finish()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T20:54:09.567399Z",
     "start_time": "2024-11-11T20:19:09.671874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Name: emb_dim_256-n_heads_8-trans_h_dim_512-class_h_dim_128-dropout_0.2-lr_0.0001-warmup_100-w_decay_0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: aintnoair. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20241111_211910-feb023ms</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aintnoair/nlp_p3_transformer/runs/feb023ms' target=\"_blank\">emb_dim_256-n_heads_8-trans_h_dim_512-class_h_dim_128-dropout_0.2-lr_0.0001-warmup_100-w_decay_0.0001</a></strong> to <a href='https://wandb.ai/aintnoair/nlp_p3_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aintnoair/nlp_p3_transformer' target=\"_blank\">https://wandb.ai/aintnoair/nlp_p3_transformer</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aintnoair/nlp_p3_transformer/runs/feb023ms' target=\"_blank\">https://wandb.ai/aintnoair/nlp_p3_transformer/runs/feb023ms</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "C:\\Users\\Pascal\\miniconda3\\envs\\nlp\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Pascal\\Documents\\nlp\\project-3\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type                  | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0  | embedding             | Embedding             | 7.4 M  | train\n",
      "1  | position_embedding    | Embedding             | 131 K  | train\n",
      "2  | input_projection      | Linear                | 131 K  | train\n",
      "3  | transformer_encoder   | TransformerEncoder    | 12.6 M | train\n",
      "4  | pooling               | AdaptiveAvgPool1d     | 0      | train\n",
      "5  | classifier            | Sequential            | 65.9 K | train\n",
      "6  | loss_fn               | CrossEntropyLoss      | 0      | train\n",
      "7  | train_accuracy        | BinaryAccuracy        | 0      | train\n",
      "8  | val_accuracy          | BinaryAccuracy        | 0      | train\n",
      "9  | test_accuracy         | BinaryAccuracy        | 0      | train\n",
      "10 | test_confusion_matrix | BinaryConfusionMatrix | 0      | train\n",
      "-------------------------------------------------------------------------\n",
      "20.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.4 M    Total params\n",
      "81.473    Total estimated model params size (MB)\n",
      "76        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pascal\\miniconda3\\envs\\nlp\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Pascal\\AppData\\Local\\Temp\\ipykernel_23712\\1889658370.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = [torch.tensor(item['input_ids']) for item in batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pascal\\miniconda3\\envs\\nlp\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 132/132 [00:33<00:00,  3.88it/s, v_num=23ms, train_accuracy=0.744]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.49it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:01, 13.63it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 13.54it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 13.43it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 13.45it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 13.42it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 13.42it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.42it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.43it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.45it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.46it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.46it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.47it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.46it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.44it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 13.68it/s]\n",
      "Epoch 0: 100%|██████████| 132/132 [00:35<00:00,  3.75it/s, v_num=23ms, train_accuracy=0.744, val_loss=0.684, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved. New best score: 0.595\n",
      "Epoch 0, global step 132: 'val_accuracy' reached 0.59500 (best 0.59500), saving model to 'C:\\\\Users\\\\Pascal\\\\Documents\\\\nlp\\\\project-3\\\\checkpoints\\\\emb_dim_256-n_heads_8-trans_h_dim_512-class_h_dim_128-dropout_0.2-lr_0.0001-warmup_100-w_decay_0.0001-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 132/132 [00:33<00:00,  3.94it/s, v_num=23ms, train_accuracy=0.535, val_loss=0.684, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.93it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.32it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.17it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.08it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.08it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.11it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.42it/s]\n",
      "Epoch 1: 100%|██████████| 132/132 [00:34<00:00,  3.81it/s, v_num=23ms, train_accuracy=0.535, val_loss=0.681, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 264: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 132/132 [00:33<00:00,  3.99it/s, v_num=23ms, train_accuracy=0.721, val_loss=0.681, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.42it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.80it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.60it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.33it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.18it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.08it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.07it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.39it/s]\n",
      "Epoch 2: 100%|██████████| 132/132 [00:34<00:00,  3.86it/s, v_num=23ms, train_accuracy=0.721, val_loss=0.677, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 396: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 132/132 [00:34<00:00,  3.77it/s, v_num=23ms, train_accuracy=0.767, val_loss=0.677, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.51it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.62it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.30it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.24it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.17it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.06it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.05it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.03it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.00it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.01it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.01it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.02it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.05it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.36it/s]\n",
      "Epoch 3: 100%|██████████| 132/132 [00:36<00:00,  3.65it/s, v_num=23ms, train_accuracy=0.767, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 528: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:33<00:00,  3.90it/s, v_num=23ms, train_accuracy=0.721, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.22it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.55it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.16it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.13it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.45it/s]\n",
      "Epoch 4: 100%|██████████| 132/132 [00:34<00:00,  3.77it/s, v_num=23ms, train_accuracy=0.721, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 660: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 132/132 [00:33<00:00,  3.99it/s, v_num=23ms, train_accuracy=0.581, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.91it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.32it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.20it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.50it/s]\n",
      "Epoch 5: 100%|██████████| 132/132 [00:34<00:00,  3.86it/s, v_num=23ms, train_accuracy=0.581, val_loss=0.680, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 792: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 132/132 [00:33<00:00,  3.99it/s, v_num=23ms, train_accuracy=0.721, val_loss=0.680, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.52it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.76it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.36it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.07it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 13.80it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 13.80it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.85it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.88it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.91it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.94it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.95it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.97it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.29it/s]\n",
      "Epoch 6: 100%|██████████| 132/132 [00:34<00:00,  3.86it/s, v_num=23ms, train_accuracy=0.721, val_loss=0.677, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 924: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 132/132 [00:33<00:00,  3.99it/s, v_num=23ms, train_accuracy=0.605, val_loss=0.677, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.98it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.36it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.24it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.18it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.05it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.06it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.07it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.08it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.38it/s]\n",
      "Epoch 7: 100%|██████████| 132/132 [00:34<00:00,  3.86it/s, v_num=23ms, train_accuracy=0.605, val_loss=0.679, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 1056: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 132/132 [00:33<00:00,  3.99it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.679, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.17it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.42it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.41it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.36it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.33it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.16it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.09it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.41it/s]\n",
      "Epoch 8: 100%|██████████| 132/132 [00:34<00:00,  3.86it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.682, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1188: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 132/132 [00:33<00:00,  3.96it/s, v_num=23ms, train_accuracy=0.488, val_loss=0.682, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.25it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.38it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.16it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.08it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.07it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.99it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.28it/s]\n",
      "Epoch 9: 100%|██████████| 132/132 [00:34<00:00,  3.83it/s, v_num=23ms, train_accuracy=0.488, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1320: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 132/132 [00:33<00:00,  4.00it/s, v_num=23ms, train_accuracy=0.605, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.74it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.18it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.00it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.01it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.03it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 13.98it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.94it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.91it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.88it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.88it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.92it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.90it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.17it/s]\n",
      "Epoch 10: 100%|██████████| 132/132 [00:34<00:00,  3.86it/s, v_num=23ms, train_accuracy=0.605, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 1452: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 12.72it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:01, 12.34it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:01, 12.18it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 12.07it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 12.03it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 12.04it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 12.04it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 12.04it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 12.06it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 12.05it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 12.04it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 12.04it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:01<00:00, 12.04it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 12.04it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 12.04it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 12.27it/s]\n",
      "Epoch 11: 100%|██████████| 132/132 [00:35<00:00,  3.70it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.677, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1584: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 132/132 [00:34<00:00,  3.85it/s, v_num=23ms, train_accuracy=0.488, val_loss=0.677, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.73it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.02it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.03it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.00it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.01it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.99it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.00it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.02it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.03it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.03it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.33it/s]\n",
      "Epoch 12: 100%|██████████| 132/132 [00:35<00:00,  3.73it/s, v_num=23ms, train_accuracy=0.488, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1716: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 132/132 [00:34<00:00,  3.81it/s, v_num=23ms, train_accuracy=0.698, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 13.07it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:01, 12.52it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:01, 12.41it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 12.31it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 12.25it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 12.22it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 12.18it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 12.16it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 12.15it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 12.13it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 12.12it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 12.09it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:01<00:00, 12.08it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 12.08it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 12.07it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 12.33it/s]\n",
      "Epoch 13: 100%|██████████| 132/132 [00:35<00:00,  3.67it/s, v_num=23ms, train_accuracy=0.698, val_loss=0.680, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 1848: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 132/132 [00:34<00:00,  3.87it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.680, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.28it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.71it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.61it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.45it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.41it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.38it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.34it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.24it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.23it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.54it/s]\n",
      "Epoch 14: 100%|██████████| 132/132 [00:35<00:00,  3.75it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 1980: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 132/132 [00:35<00:00,  3.70it/s, v_num=23ms, train_accuracy=0.558, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 12.32it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:01, 12.07it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:01, 11.86it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:01, 11.81it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 11.79it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 11.77it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 11.77it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 11.98it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 12.19it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 12.32it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 12.47it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 12.59it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:01<00:00, 12.70it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 12.79it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 12.88it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 13.20it/s]\n",
      "Epoch 15: 100%|██████████| 132/132 [00:36<00:00,  3.58it/s, v_num=23ms, train_accuracy=0.558, val_loss=0.679, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 2112: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 132/132 [00:34<00:00,  3.82it/s, v_num=23ms, train_accuracy=0.651, val_loss=0.679, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.34it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.52it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.40it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.01it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.97it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.97it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.01it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.99it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.96it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.94it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.97it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.98it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.28it/s]\n",
      "Epoch 16: 100%|██████████| 132/132 [00:35<00:00,  3.69it/s, v_num=23ms, train_accuracy=0.651, val_loss=0.677, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 2244: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 132/132 [00:34<00:00,  3.82it/s, v_num=23ms, train_accuracy=0.581, val_loss=0.677, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.30it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.44it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.02it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.00it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.03it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.03it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.06it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.08it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.06it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.07it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.08it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.08it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.09it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.41it/s]\n",
      "Epoch 17: 100%|██████████| 132/132 [00:35<00:00,  3.70it/s, v_num=23ms, train_accuracy=0.581, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 2376: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 132/132 [00:34<00:00,  3.85it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.13it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.60it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.44it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.32it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.06it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.05it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.00it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.97it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.99it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.98it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.97it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.98it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.00it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.31it/s]\n",
      "Epoch 18: 100%|██████████| 132/132 [00:35<00:00,  3.73it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.680, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 2508: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 132/132 [00:34<00:00,  3.82it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.680, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 12.61it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:01, 12.20it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:01, 12.11it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 12.09it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 12.38it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 12.62it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 12.82it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 12.98it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.12it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.22it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.31it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.33it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.40it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.45it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.46it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 13.76it/s]\n",
      "Epoch 19: 100%|██████████| 132/132 [00:35<00:00,  3.69it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.675, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 2640: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 132/132 [00:34<00:00,  3.85it/s, v_num=23ms, train_accuracy=0.698, val_loss=0.675, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.01it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.53it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.31it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.02it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 13.98it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 13.91it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.91it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.94it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.95it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.89it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.88it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.85it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.16it/s]\n",
      "Epoch 20: 100%|██████████| 132/132 [00:35<00:00,  3.73it/s, v_num=23ms, train_accuracy=0.698, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 2772: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 132/132 [00:34<00:00,  3.83it/s, v_num=23ms, train_accuracy=0.581, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 12.17it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:01, 12.06it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:01, 12.06it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 12.01it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 12.38it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 12.64it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 12.87it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 12.97it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.07it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.19it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.27it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.34it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.40it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.42it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.47it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 13.79it/s]\n",
      "Epoch 21: 100%|██████████| 132/132 [00:35<00:00,  3.70it/s, v_num=23ms, train_accuracy=0.581, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 2904: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 132/132 [00:34<00:00,  3.88it/s, v_num=23ms, train_accuracy=0.651, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.33it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.60it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.42it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.37it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.35it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.32it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.34it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.30it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.28it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.22it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.52it/s]\n",
      "Epoch 22: 100%|██████████| 132/132 [00:35<00:00,  3.76it/s, v_num=23ms, train_accuracy=0.651, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 3036: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 132/132 [00:34<00:00,  3.81it/s, v_num=23ms, train_accuracy=0.512, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 12.46it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:01, 12.26it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:01, 12.12it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:01, 12.00it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 11.94it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 11.89it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 11.98it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 12.12it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 12.25it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 12.32it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 12.43it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 12.55it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:01<00:00, 12.66it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 12.76it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 12.81it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 13.11it/s]\n",
      "Epoch 23: 100%|██████████| 132/132 [00:35<00:00,  3.68it/s, v_num=23ms, train_accuracy=0.512, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 3168: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 132/132 [00:34<00:00,  3.86it/s, v_num=23ms, train_accuracy=0.744, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.17it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.36it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.18it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.16it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.16it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.13it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.43it/s]\n",
      "Epoch 24: 100%|██████████| 132/132 [00:35<00:00,  3.73it/s, v_num=23ms, train_accuracy=0.744, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 3300: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 132/132 [00:34<00:00,  3.85it/s, v_num=23ms, train_accuracy=0.558, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.67it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.36it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.18it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.05it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.02it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.05it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.03it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.00it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.95it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.94it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.88it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.83it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.84it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.86it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.15it/s]\n",
      "Epoch 25: 100%|██████████| 132/132 [00:35<00:00,  3.72it/s, v_num=23ms, train_accuracy=0.558, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 3432: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 132/132 [00:34<00:00,  3.87it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.10it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.70it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.42it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.36it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.98it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.96it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.99it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.99it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.98it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.99it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.01it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.33it/s]\n",
      "Epoch 26: 100%|██████████| 132/132 [00:35<00:00,  3.74it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.677, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 3564: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 132/132 [00:34<00:00,  3.82it/s, v_num=23ms, train_accuracy=0.698, val_loss=0.677, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 12.86it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:01, 12.43it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:01, 12.26it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 12.19it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 12.19it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 12.14it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 12.11it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 12.10it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 12.09it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 12.08it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 12.05it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:01<00:00, 11.93it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:01<00:00, 11.92it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 11.94it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 11.88it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 12.09it/s]\n",
      "Epoch 27: 100%|██████████| 132/132 [00:35<00:00,  3.68it/s, v_num=23ms, train_accuracy=0.698, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 3696: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.05it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.38it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.02it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 13.89it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 13.79it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.81it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.81it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.85it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.87it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.88it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.85it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.82it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.83it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.13it/s]\n",
      "Epoch 28: 100%|██████████| 132/132 [00:35<00:00,  3.72it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 3828: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 132/132 [00:34<00:00,  3.80it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 12.37it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:01, 12.05it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:01, 12.03it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 12.00it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 12.00it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 11.98it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 11.98it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 11.98it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 12.05it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 12.21it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 12.37it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 12.50it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:01<00:00, 12.63it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 12.73it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 12.82it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 13.14it/s]\n",
      "Epoch 29: 100%|██████████| 132/132 [00:35<00:00,  3.67it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 3960: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 132/132 [00:34<00:00,  3.85it/s, v_num=23ms, train_accuracy=0.558, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.19it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.48it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.37it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.34it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.28it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.20it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.49it/s]\n",
      "Epoch 30: 100%|██████████| 132/132 [00:35<00:00,  3.72it/s, v_num=23ms, train_accuracy=0.558, val_loss=0.677, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, global step 4092: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 132/132 [00:35<00:00,  3.73it/s, v_num=23ms, train_accuracy=0.558, val_loss=0.677, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 13.22it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:01, 12.58it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 13.02it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 13.24it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 13.37it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 13.15it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 12.88it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 12.66it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 12.56it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 12.48it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 12.48it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 12.57it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:01<00:00, 12.68it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 12.78it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 12.84it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 13.17it/s]\n",
      "Epoch 31: 100%|██████████| 132/132 [00:36<00:00,  3.60it/s, v_num=23ms, train_accuracy=0.558, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, global step 4224: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 132/132 [00:34<00:00,  3.79it/s, v_num=23ms, train_accuracy=0.512, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.30it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.63it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.48it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.27it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.07it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.06it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.06it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.08it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.05it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.01it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.99it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.29it/s]\n",
      "Epoch 32: 100%|██████████| 132/132 [00:35<00:00,  3.67it/s, v_num=23ms, train_accuracy=0.512, val_loss=0.683, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, global step 4356: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 132/132 [00:33<00:00,  3.90it/s, v_num=23ms, train_accuracy=0.605, val_loss=0.683, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.11it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.66it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.40it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.31it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.27it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.18it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.17it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.16it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.17it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.18it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.15it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.47it/s]\n",
      "Epoch 33: 100%|██████████| 132/132 [00:34<00:00,  3.77it/s, v_num=23ms, train_accuracy=0.605, val_loss=0.677, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, global step 4488: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 132/132 [00:33<00:00,  3.97it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.677, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.16it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.62it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.44it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.12it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.43it/s]\n",
      "Epoch 34: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.675, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, global step 4620: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 132/132 [00:33<00:00,  3.95it/s, v_num=23ms, train_accuracy=0.558, val_loss=0.675, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.99it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.39it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.24it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.24it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.17it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.07it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.03it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.00it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.01it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.02it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.03it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.32it/s]\n",
      "Epoch 35: 100%|██████████| 132/132 [00:34<00:00,  3.82it/s, v_num=23ms, train_accuracy=0.558, val_loss=0.665, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35, global step 4752: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 132/132 [00:32<00:00,  4.01it/s, v_num=23ms, train_accuracy=0.721, val_loss=0.665, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.34it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.73it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.57it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.49it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.45it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.44it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.35it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.32it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.18it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.16it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.17it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.16it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.48it/s]\n",
      "Epoch 36: 100%|██████████| 132/132 [00:34<00:00,  3.87it/s, v_num=23ms, train_accuracy=0.721, val_loss=0.684, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36, global step 4884: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 132/132 [00:32<00:00,  4.00it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.684, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.39it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.78it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.60it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.52it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.43it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.40it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.31it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.28it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.21it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.52it/s]\n",
      "Epoch 37: 100%|██████████| 132/132 [00:34<00:00,  3.87it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37, global step 5016: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 132/132 [00:32<00:00,  4.01it/s, v_num=23ms, train_accuracy=0.535, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.26it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.64it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.52it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.46it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.42it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.31it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.17it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.48it/s]\n",
      "Epoch 38: 100%|██████████| 132/132 [00:34<00:00,  3.87it/s, v_num=23ms, train_accuracy=0.535, val_loss=0.681, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38, global step 5148: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 132/132 [00:33<00:00,  3.99it/s, v_num=23ms, train_accuracy=0.605, val_loss=0.681, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.15it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.77it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.56it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.41it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.36it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.32it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.30it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.31it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.30it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.28it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.26it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.57it/s]\n",
      "Epoch 39: 100%|██████████| 132/132 [00:34<00:00,  3.86it/s, v_num=23ms, train_accuracy=0.605, val_loss=0.681, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 5280: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 132/132 [00:32<00:00,  4.01it/s, v_num=23ms, train_accuracy=0.721, val_loss=0.681, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.18it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.65it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.32it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.24it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.20it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.49it/s]\n",
      "Epoch 40: 100%|██████████| 132/132 [00:34<00:00,  3.88it/s, v_num=23ms, train_accuracy=0.721, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40, global step 5412: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 132/132 [00:32<00:00,  4.00it/s, v_num=23ms, train_accuracy=0.791, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.96it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.17it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.00it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 13.75it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 13.63it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 13.58it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 13.53it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.53it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.56it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.58it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.61it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.61it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.63it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.62it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.64it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 13.90it/s]\n",
      "Epoch 41: 100%|██████████| 132/132 [00:34<00:00,  3.87it/s, v_num=23ms, train_accuracy=0.791, val_loss=0.680, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41, global step 5544: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 132/132 [00:33<00:00,  3.97it/s, v_num=23ms, train_accuracy=0.767, val_loss=0.680, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.16it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.35it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 13.90it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 13.74it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 13.75it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 13.78it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 13.81it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.83it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.84it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.84it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.88it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.89it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.86it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.85it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.86it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.12it/s]\n",
      "Epoch 42: 100%|██████████| 132/132 [00:34<00:00,  3.83it/s, v_num=23ms, train_accuracy=0.767, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42, global step 5676: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 132/132 [00:33<00:00,  3.96it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.38it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.77it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.47it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 13.99it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 13.98it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.95it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.91it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.95it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.92it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.24it/s]\n",
      "Epoch 43: 100%|██████████| 132/132 [00:34<00:00,  3.83it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.677, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43, global step 5808: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 132/132 [00:33<00:00,  3.97it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.677, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.27it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.48it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.30it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 13.92it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 13.90it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 13.87it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.88it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.85it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.84it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.83it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.86it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.89it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.92it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.94it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.25it/s]\n",
      "Epoch 44: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44, global step 5940: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 132/132 [00:33<00:00,  3.96it/s, v_num=23ms, train_accuracy=0.535, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.92it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.59it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.38it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.32it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.28it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.24it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.24it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.24it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.55it/s]\n",
      "Epoch 45: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.535, val_loss=0.680, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45, global step 6072: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 132/132 [00:33<00:00,  3.97it/s, v_num=23ms, train_accuracy=0.605, val_loss=0.680, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.62it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.33it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.07it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.10it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.41it/s]\n",
      "Epoch 46: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.605, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46, global step 6204: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 132/132 [00:33<00:00,  3.95it/s, v_num=23ms, train_accuracy=0.512, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.49it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:01, 13.69it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 13.55it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 13.62it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 13.74it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 13.79it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 13.83it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.84it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.87it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.91it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.93it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.94it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.96it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.96it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.97it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.27it/s]\n",
      "Epoch 47: 100%|██████████| 132/132 [00:34<00:00,  3.82it/s, v_num=23ms, train_accuracy=0.512, val_loss=0.680, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47, global step 6336: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 132/132 [00:33<00:00,  3.96it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.680, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.07it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.65it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.43it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.41it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.42it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.37it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.28it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.08it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.03it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.03it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.05it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.02it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.03it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.35it/s]\n",
      "Epoch 48: 100%|██████████| 132/132 [00:34<00:00,  3.83it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.680, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48, global step 6468: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 132/132 [00:33<00:00,  3.98it/s, v_num=23ms, train_accuracy=0.651, val_loss=0.680, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.99it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.64it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.50it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.06it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 13.96it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.90it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.88it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.77it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.77it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.78it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.80it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.79it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.79it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.10it/s]\n",
      "Epoch 49: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.651, val_loss=0.677, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 6600: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 132/132 [00:33<00:00,  3.97it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.677, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.18it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.70it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.49it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.36it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.24it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.17it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.06it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.06it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.06it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.33it/s]\n",
      "Epoch 50: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.677, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50, global step 6732: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 132/132 [00:33<00:00,  3.96it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.677, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.42it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.75it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.57it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.48it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.40it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.37it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.30it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.18it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.50it/s]\n",
      "Epoch 51: 100%|██████████| 132/132 [00:34<00:00,  3.83it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.680, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51, global step 6864: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 132/132 [00:33<00:00,  3.98it/s, v_num=23ms, train_accuracy=0.837, val_loss=0.680, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.58it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.32it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.27it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.16it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.01it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.06it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.08it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.14it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.44it/s]\n",
      "Epoch 52: 100%|██████████| 132/132 [00:34<00:00,  3.85it/s, v_num=23ms, train_accuracy=0.837, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52, global step 6996: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 132/132 [00:33<00:00,  3.98it/s, v_num=23ms, train_accuracy=0.721, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.07it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.66it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.43it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.08it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.05it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.03it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.02it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.02it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.04it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.05it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.07it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.08it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.36it/s]\n",
      "Epoch 53: 100%|██████████| 132/132 [00:34<00:00,  3.85it/s, v_num=23ms, train_accuracy=0.721, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53, global step 7128: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 132/132 [00:33<00:00,  3.97it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.14it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.51it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.24it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.16it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.17it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.12it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.42it/s]\n",
      "Epoch 54: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.678, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54, global step 7260: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 132/132 [00:33<00:00,  3.96it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.678, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.17it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.49it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.40it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.25it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.20it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.21it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.21it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.50it/s]\n",
      "Epoch 55: 100%|██████████| 132/132 [00:34<00:00,  3.83it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55, global step 7392: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 132/132 [00:33<00:00,  3.98it/s, v_num=23ms, train_accuracy=0.605, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.18it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.19it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.18it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 13.98it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 13.78it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 13.76it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 13.73it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 13.65it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 13.72it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 13.74it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 13.77it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 13.80it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:01<00:00, 13.82it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 13.82it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.13it/s]\n",
      "Epoch 56: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.605, val_loss=0.677, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56, global step 7524: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 132/132 [00:33<00:00,  3.96it/s, v_num=23ms, train_accuracy=0.488, val_loss=0.677, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01, 14.97it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.56it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.43it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.37it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.31it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.26it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.15it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.17it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.16it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.14it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.12it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.44it/s]\n",
      "Epoch 57: 100%|██████████| 132/132 [00:34<00:00,  3.83it/s, v_num=23ms, train_accuracy=0.488, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57, global step 7656: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 132/132 [00:33<00:00,  3.97it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.676, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.09it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.66it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.24it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.08it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.07it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.09it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.10it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.12it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.11it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.13it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.13it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.45it/s]\n",
      "Epoch 58: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.628, val_loss=0.683, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58, global step 7788: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 132/132 [00:33<00:00,  3.97it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.683, val_accuracy=0.595]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:00, 15.46it/s]\n",
      "Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.77it/s]\n",
      "Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 14.56it/s]\n",
      "Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 14.43it/s]\n",
      "Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 14.35it/s]\n",
      "Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 14.33it/s]\n",
      "Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 14.30it/s]\n",
      "Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 14.29it/s]\n",
      "Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 14.23it/s]\n",
      "Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 14.22it/s]\n",
      "Validation DataLoader 0:  94%|█████████▍| 15/16 [00:01<00:00, 14.19it/s]\n",
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:01<00:00, 14.44it/s]\n",
      "Epoch 59: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.676, val_accuracy=0.595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 7920: 'val_accuracy' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 132/132 [00:34<00:00,  3.84it/s, v_num=23ms, train_accuracy=0.674, val_loss=0.676, val_accuracy=0.595]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_accuracy</td><td>█▄▅▃▆█▆█▅▇▆▅▅▄▄▃▃▃▆▅▄▅▆▅▇▄▇▅▆▆▇▅▇▁▆▃▅▅▆█</td></tr><tr><td>train_loss</td><td>▇▃██▅▄▄█▃▅▆▆▅▆▁▂▇▃▆▇▄▆▅▇█▄▇█▇█▄▄▄▄█▇▇▃▇█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▅▆▅▇▆▆▅▅▅▆▅▅▅▆▆▆▆▇▅▁█▅▇▅▇▅▅▆▅▇▆▅▆▆▆▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>59</td></tr><tr><td>train_accuracy</td><td>0.6875</td></tr><tr><td>train_loss</td><td>0.6314</td></tr><tr><td>trainer/global_step</td><td>7919</td></tr><tr><td>val_accuracy</td><td>0.595</td></tr><tr><td>val_loss</td><td>0.67564</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">emb_dim_256-n_heads_8-trans_h_dim_512-class_h_dim_128-dropout_0.2-lr_0.0001-warmup_100-w_decay_0.0001</strong> at: <a href='https://wandb.ai/aintnoair/nlp_p3_transformer/runs/feb023ms' target=\"_blank\">https://wandb.ai/aintnoair/nlp_p3_transformer/runs/feb023ms</a><br/> View project at: <a href='https://wandb.ai/aintnoair/nlp_p3_transformer' target=\"_blank\">https://wandb.ai/aintnoair/nlp_p3_transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241111_211910-feb023ms\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:54:11.053670Z",
     "start_time": "2024-11-11T20:54:09.604244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_label_distribution_from_boolq(train_data, val_data):\n",
    "    train_yes_count = sum(1 for label in train_data['answer'] if label == 1)\n",
    "    train_no_count = sum(1 for label in train_data['answer'] if label == 0)\n",
    "    val_yes_count = sum(1 for label in val_data['answer'] if label == 1)\n",
    "    val_no_count = sum(1 for label in val_data['answer'] if label == 0)\n",
    "    \n",
    "    train_total = train_yes_count + train_no_count\n",
    "    val_total = val_yes_count + val_no_count\n",
    "    train_yes_percent = (train_yes_count / train_total) * 100\n",
    "    train_no_percent = (train_no_count / train_total) * 100\n",
    "    val_yes_percent = (val_yes_count / val_total) * 100\n",
    "    val_no_percent = (val_no_count / val_total) * 100\n",
    "    \n",
    "    labels = [\"No\", \"Yes\"]\n",
    "    train_counts = [train_no_count, train_yes_count]\n",
    "    val_counts = [val_no_count, val_yes_count]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    ax[0].bar(labels, train_counts, color='blue', alpha=0.7)\n",
    "    ax[0].set_title(\"Training Label Distribution\")\n",
    "    ax[0].set_xlabel(\"Labels\")\n",
    "    ax[0].set_ylabel(\"Count\")\n",
    "    ax[0].set_ylim(0, max(train_counts + val_counts) * 1.1)  # Consistent y-axis scale\n",
    "    for i, v in enumerate(train_counts):\n",
    "        ax[0].text(i, v + 50, f\"{v} ({train_no_percent if i == 0 else train_yes_percent:.2f}%)\", ha='center', color='black')\n",
    "    \n",
    "    ax[1].bar(labels, val_counts, color='orange', alpha=0.7)\n",
    "    ax[1].set_title(\"Validation Label Distribution\")\n",
    "    ax[1].set_xlabel(\"Labels\")\n",
    "    ax[1].set_ylabel(\"Count\")\n",
    "    ax[1].set_ylim(0, max(train_counts + val_counts) * 1.1)  # Consistent y-axis scale\n",
    "    for i, v in enumerate(val_counts):\n",
    "        ax[1].text(i, v + 20, f\"{v} ({val_no_percent if i == 0 else val_yes_percent:.2f}%)\", ha='center', color='black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Assuming train_data and validation_data are loaded datasets\n",
    "plot_label_distribution_from_boolq(train_data, validation_data)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAJOCAYAAADMCCWlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB+k0lEQVR4nOzdd3xN9x/H8fdNIhESIkOMGLVXRJrYW6mV0qJDW9QoKqGt0VIr1KhZNaI1SrWUWh1o/apGqxSNWlW7lJgRK4Ss+/vDL+fnSmiQcSSv5+NxHw/3fM/4nptzj0/eOed7LFar1SoAAAAAAAAAgCnYZXYHAAAAAAAAAAD/R2gLAAAAAAAAACZCaAsAAAAAAAAAJkJoCwAAAAAAAAAmQmgLAAAAAAAAACZCaAsAAAAAAAAAJkJoCwAAAAAAAAAmQmgLAAAAAAAAACZCaAsAyFRWqzVbbx8AACCtUNeYjxl+JmboA4AHR2gLIN0NHDhQZcuWve+rQ4cOj7SNadOmqWzZsum+zMNKq22dOnVKZcuW1YoVKx55XR06dLjv575t27ZkP6dKlSqpbt266tevn44cOWIz/4oVK1S2bFmdOnUqVdu/evWq3nnnHf3+++/3ne/ufX7Q7dzPTz/9pHfffdd4n7TP27Zte+R1AwCAx1Pnzp1VrVo1xcbG3nOeZ555Rq+88kqq1teoUSMNHDhQUupruTuXSa3w8HB1797deJ+WdeO/ycgaNbVSUzM2atTIptYtX768AgMD1b59e3399dfJ5i9btqymTZuW6j4sXbpU48aN+9f57t7nB93OvZw9e1bdu3dXRESEMe1hji0AmcMhszsAIOvr1auXXnrpJeN9WFiY9u/fr+nTpxvTXFxcHmkbzz//vOrWrZvuy2RHw4YNU8WKFSVJN2/e1MmTJzVnzhy1a9dO8+fPV5UqVSRJDRo00JIlS5Q/f/5Urfevv/7SN998o7Zt2953vvz582vJkiUqWrToI+1HSubPn2/zvmLFilqyZIlKlSqV5tsCAACPh7Zt22rLli36+eef1bhx42Ttf/75pw4dOpSqMO5u6VnXLF26VEePHs2QbWUl9evXV69evSRJ8fHxunTpkr7//nu9++67+uuvvzRo0CBj3iVLlqhAgQKpXvfMmTNVrVq1f51v+PDhD97xVNiyZYs2bdpkM2369OmP/LsXgIxBaAsg3RUtWtSmWHR3d5ejo6MR9qWFAgUKPFAB9bDLZEelSpWy+VnVqFFDTZs2VZs2bTRw4ECtXr1a9vb2cnd3l7u7e5pvP62PlftxcXHJsG0BAABzatKkifLmzatvv/02xdB25cqVcnFxUdOmTR943RlZ12Tkth5n7u7uyT6nJk2ayMvLS/Pnz9fTTz+tgIAASUq3zzMjLxioUKFChm0LwKNheAQAprFixQpVqFBBS5cuVe3atVWtWjUdOXJECQkJmjVrloKCglS5cmVVqVJFL730kn777Tdj2buHH+jQoYMGDx6sWbNmqUGDBvL19dVLL72kPXv2PNIykrRx40a1adNGlStXVtOmTbVq1So1adIkTW5h2rFjh7p27aqqVauqUqVKatSokaZNm6bExESb+c6dO6cePXqocuXKql+/vqZOnaqEhASbeZYuXaqWLVuqUqVKatCggaZNm5ZsnoeVJ08edevWTX///be2b98uKfktaFFRUerXr59q164tX19ftW7d2rjNbNu2berYsaMkqWPHjsbtYB06dFD//v3Vp08fValSRZ07d77n7XY7d+7Us88+q0qVKikoKEhr1qwx2u41zMGdt5516NBB27dv1/bt2415U1pu79696tq1q6pXr64nn3xSPXv21OHDh5Nta+vWrerSpYv8/PxUu3ZtTZgwIc0+bwAAkHGcnJwUFBSkjRs3Kjo62qYtLi5Oq1evVsuWLeXs7KyoqCiNGDFCDRs2VKVKlVStWjUFBwff85b8lOqaAwcOqHPnzvL391fDhg317bffJlvu37YzcOBArVy5UhEREcb6U9rW8ePH1adPH9WuXVtVqlRRhw4dFB4enqx/33//vfr06SN/f39Vq1ZNQ4YM0Y0bNx7pc03NftxpxowZqlWrlvz9/dWrVy+dPHnSpv3QoUPq0aOHnnzyST355JMKDg5ONs+jCAkJkZOTkxYvXmxMu3vYgs8++0zNmjWTr6+v6tatq9DQUOOYadSokSIiIrRy5UqjRr7X7zspDQkRHR2t/v37y9/fXzVr1tSoUaMUExNjtKc0zMGd9fiKFSuMq4SfeuopY967l7t27ZrGjh2rxo0by9fXV0FBQVq2bJnNehs1aqSpU6dq3LhxqlWrlipXrqyuXbvq+PHjj/AJA/g3hLYATCUhIUGffvqpRo8erUGDBqlkyZKaOHGiwsLC9OKLL2rOnDl6//33dfnyZb355ps2hcvd1q5dq59++klDhgzR5MmTFRkZqd69e983SPu3ZX777Tf16tVLBQsW1LRp0/TKK69o+PDhOnPmzCPv+4EDB/Taa6/Jzc1NH374oWbOnKnAwEBNnz5d33//vc2806ZNk4eHh2bMmKG2bdvq448/trlF75NPPtHQoUNVs2ZNffzxx3rllVc0e/ZsDR069JH7maR27dqSZFPo32nAgAE6evSoRowYodmzZ6tChQp699139dtvv6lixYoaNmyYpNvDL9x5S9j333+v3Llza+bMmerWrds9tz9s2DA1b95cYWFhKl26tN5++22tW7cu1f0fPny4KlSooAoVKmjJkiXGEBB3+u2339S+fXtJ0pgxYzRq1CidOXNGL730ks3th5LUv39/BQQE6OOPP1ZQUJDmzJmjpUuXpro/AADAPNq2batbt25p7dq1NtN//vlnRUVF6fnnn5fValWPHj3066+/qn///po7d65CQkK0devWVN/ufu7cOb366qu6du2aJkyYoDfffFMTJ07UuXPnjHlSs51evXqpfv368vLy0pIlS9SgQYNk2zpy5IjatGmjU6dOaciQIZo4caIsFos6depk/BE+yfDhw1W4cGGFhYWpa9euWrZsmWbOnPmAn6KtB/m8wsPDtXr1ag0bNkyjRo3SgQMH1LFjRyMQ/fvvv/XSSy/p4sWLGjdunEaPHq2TJ0+qffv2unjx4iP1M4mrq6sqV658z1p31apVmjBhgl555RXNnTtXwcHB+uabb/T+++9Luj0MgZeXl+rXr28zhFhKv++k5PPPP9f169c1ZcoU9ejRQ0uXLlX//v1T3f8GDRrojTfeMPqSNATEnW7evKmXX35Z3333nbp166awsDAFBARo8ODB+vjjj23mXbBggY4dO6axY8dq1KhR2rdvn82zIQCkPYZHAGA6PXv2tCk0z58/r7ffftvmr89OTk7q3bu3Dh48eM/blOLj4zV37lxjzKbr168bY1NVqlTpoZaZNm2aSpcurenTp8tisUiSPDw81Ldv30fe7wMHDqhWrVqaMGGC7Oxu/02tdu3aWr9+vbZt26aWLVsa89atW1djxowx/h0dHa1FixapV69esre3N0LuIUOGSJLq1KkjNzc3DRkyRJ07d1bp0qUfub9eXl6SpAsXLqTYvn37dgUHBxu3FVarVk1ubm5ydHSUi4uLcRtYqVKlbG4Jy5Ejh0aMGCFHR0dJuueVKr1791bXrl0lSfXq1dPx48cVFhaW4m2MKSlVqpTxc77XMTRp0iQVK1ZMs2bNkr29vaTbn2WTJk00depUffTRR8a8zz//vIKDgyVJNWvW1Lp167Rx40ab8ZwBAMDjoWLFiipfvry+++47m/H3v/76a5UtW1a+vr46d+6cnJ2d9e677yowMFCSVL16df3zzz9asmRJqrYzf/58466ypGGmnnjiCb3wwgvGPOfPn//X7RQtWjTZEGR3Xxk7ffp0OTo6asGCBUYN1KBBAwUFBWn8+PE2V1fWr1/fCORq1qypX3/9VRs3blS/fv1S/RneLTX7kcTe3l6ffvqpMZRZiRIl9Oyzz+rrr7/Wq6++qunTp8vZ2Vnz58839qVmzZpq3Lix5syZk2ZhoqenZ7K77pJs375dPj4+euWVV2RnZ6dq1aopV65cunLliqTbwxA4OjqmOPzC3b/vpKRkyZKaMWOG7OzsVL9+fVksFo0ZM0aHDh1SmTJl/rXv7u7uxhB15cuXl4+PT7J5VqxYoUOHDmnx4sXy9/eXdPt3i/j4eIWFhemll16Sm5ubpNt32oWFhRk18T///KNp06bp0qVLypcv37/2B8CD40pbAKZTvnx5m/eTJk1Sp06dFBUVpd9//13Lly83bhu731N97wzlJMnb21uS7nt17v2WiY2N1R9//KGnn37aCGwlqVmzZnJwePS/gT377LOaPXu24uLidODAAa1du9YY9iAuLs5m3ubNm9u8f/rppxUXF6fdu3frjz/+0M2bN9WoUSPFx8cbr0aNGkmSfv3110fuq3T7aglJNp/FnapXr65p06apT58+Wrp0qSIjI/Xuu+/qySefvO96S5QoYQS299OiRQub940bN9b+/ft1/fr1VO7B/d24cUN79+5V8+bNjeJUul2wNmzYMNkVKUmFbpICBQqkyW2EAAAgc7Rt21bbtm0zrnq9fPmyNmzYoHbt2km6XScuWLBAAQEBOnXqlH799Vd9/vnn2rlz531r1DuFh4erSpUqNs8F8PPzU6FChYz3abEd6XbI2LBhQ5ta18HBQS1bttS+fftsaqi7Q8a0qGseZD+efPJJm2dPlC9fXkWKFNGOHTsk3b4bqlq1asqZM6dR67q4uCgwMFBbtmx5pH7eyWq13rPWrVGjhv7++2+1adNG06dP1969e/XMM88kG+YgJXf/vpOSZs2aGRdySLfrfUnGZ5AWtm/frsKFCyerY1u1aqVbt25p9+7dxjRfX1+bmjjp53O/360APBqutAVgOrly5bJ5v3fvXo0YMUJ79+6Vs7OzSpUqZRSyScFhSpydnW3eJxU9d48Pm9plLl++rISEBHl4eNjMY29vb/wF+lHcvHlT77//vr755hvFx8fLx8dH/v7+cnBwSLafSVe5Jkkq9JP+si9J3bt3T3E758+ff+S+StLZs2cl6Z4Pc/vwww/18ccf6/vvv9fatWtlZ2enWrVqaeTIkSpcuPA915s7d+5Ubd/T09PmvYeHh6xWa7Kx5x7WtWvXZLVak20nadvXrl2zmZYzZ06b93Z2dvc9PgEAgLk988wzGj9+vNasWaPOnTtr9erVslgsatWqlTHPt99+q8mTJ+vMmTNyc3NT+fLlk9UE93PlypUUr4C8u9Z71O0kbetedc3dNVRKNXFa1DWp3Y+U+unh4aGrV69Kuh2gr1mzxuaZBknS8sG4586du2et26JFCyUmJmrRokUKCwvTtGnTVLhwYfXv3z/ZxQV3u/v3nZTcfQwk/Q6S9BmkhStXriTbjvT/z//ObT3M71YAHg2hLQBTi46OVrdu3VS2bFmtXr1aJUqUkJ2dnTZt2pRsjLH05uHhoRw5cigyMtJmelKg+6hGjx6ttWvXasqUKapVq5ZRzNWsWTPZvHeGs5KMPnl4eBhX5U6cOFHFixdPtmxKRfDDSLqKoWrVqim2u7q6asCAARowYICOHTumn376SWFhYRoxYoRmzZr1yNu/+xePyMhI2dvbK2/evMYVEXcXkdevX091KOzq6iqLxZLs5y3dHhIiLYJ6AABgXm5ubmrcuLG+++47de7cWd98842aNGli1AC///673n33XXXo0EFdu3Y17tAaP378PcdBvVu+fPlSrDXurC3TYjuSlDdv3nvWNUl9Sas/7qfkQfbj7lo3qZ9JV4S6urqqVq1a6ty5c7L50uIOuKQ+/Pnnn2rduvU95wkKClJQUJCuXbumzZs3a/bs2RowYIACAgKM/XtYd/9+kfRzuvMCkruf1fGgV0PnzZtXJ06cSDb9zmMCQOZheAQApnbs2DFdvnxZHTt2VKlSpYy/6P7888+SMvYvu/b29nryySf1008/2Uxfv3694uPjH3n94eHhql69uho3bmwEtvv27VNUVFSy/dy4caPN+9WrV8vZ2Vl+fn7y8/NTjhw5dO7cOfn6+hovBwcHTZ48+Z5jxD6I6OhozZs3T2XLlk1xuIOIiAjVr19fP/zwg6TbQx68/vrrqlWrlk6fPi1JNrdXPYw7P4PExET98MMP8vPzU86cOY3b/pKuBpZuF953PzzszlvO7pYrVy5VqlRJ33//vU1BfO3aNW3cuFEBAQGP1H8AAGB+bdu21Z9//qnt27dr9+7dxtAIkvTHH38oMTFRvXv3NgK6hIQE4w/bqalTa9SooT/++MPmwWNHjhzRyZMnH3g796trpNt/aN+wYYPNFbUJCQlavXq1fH19UzU81aN4kM8rPDzc5q6m3bt3KyIiQjVq1JB0+1kJR44cUfny5Y1at1KlSpo/f75+/PHHNOnvxx9/rLi4OL344osptr/11lvG8wxcXV3VvHlz9erVS/Hx8Ub4/W8/k/tJ+n0nSdKV3tWqVZMkubi42NS6UvIHBKfmmIiIiNAff/xhM/3bb79Vjhw5VLly5YftPoA0wJW2AEztiSeekIuLiz7++GM5ODjIwcFBa9euNR6UkNFjKPXp00cdOnRQnz591K5dO50+fdp4GNW9xru60/z585NNy5Mnj9q0aaPKlSvr+++/15dffqmSJUvqwIEDmjlzpiwWS7L9/M9//iNvb2/VqlVLmzdv1pIlS/Tmm28aYWW3bt300UcfKTo6WtWrV9e5c+f00UcfyWKxqFy5cg+0z0eOHJGTk5Mk6datWzp27Jg+//xzXbp0yVjn3QoXLqwCBQpo1KhRio6OVtGiRbVv3z5t2rRJPXr0kHS7uJVuh6958+Z94H5NmTJFCQkJKliwoL788kv9/fffmjdvniSpbNmyKliwoGbMmCEXFxdZLBZ98sknyW7rypMnj/744w9t3bpVFSpUSLaNfv36qWvXrurevbtefvllxcXFadasWYqNjTWKdAAAkHXVqlVLhQoV0tChQ+Xj42NzB1RSoDVy5Ei1bdtWV65c0cKFC3XgwAFJt696vHP82JR06tRJy5YtU9euXdW7d28lJCToww8/VI4cOR54O3ny5FFkZKQ2bdqU4pipISEh+vnnn9WxY0d1795dOXLk0BdffKGTJ09qzpw5j/ZB/c+vv/6a4u37zZs3f6DPKzExUd27d1fPnj116dIlTZo0SWXKlDGGpujVq5deeukl9ejRQ+3bt5eTk5OWLFmidevWaerUqQ/U56ioKO3atUvS7RD54sWLWrt2rVatWqWePXvK19c3xeVq1Kih4cOHa9y4capXr56uXr2q6dOnq3jx4kZdmydPHu3fv1/bt29/4AB07969Gjx4sIKCgrR3715NnTpV7dq1M+6ka9iwoT755BN98skn8vPz0/r16/Xbb7/ZrCNPnjySpB9//FH16tVTyZIlbdrbtGmjRYsWKTg4WH369JGPj4/Wr1+v5cuXKyQkxFgeQOYgtAVgaq6urgoLC9P48eP15ptvKnfu3Cpfvry++OILvf766/r999+NB2xlhMDAQE2bNk0fffSRevXqpcKFC2vo0KF6++23U3Xb/dixY5NNK1q0qNq0aaOBAwcqLi5OU6ZMUWxsrHx8fPTGG2/oyJEjWr9+vc3VnoMHD9bq1as1f/58eXl56b333lPHjh2N9rfeekteXl5atGiR5syZo7x586pmzZrq27evEZam1siRI41/58iRQ/nz51eNGjXUo0cPFStW7J7LTZ8+XZMnT9ZHH32kS5cuqWDBggoJCTHG2i1durSCgoK0cOFC/fLLL1q1atUD9Wvs2LH64IMPdOLECZUpU0azZ882rjywt7fX1KlTNWbMGPXt21eenp7q1KmTjh07pr///ttYxyuvvKJ9+/bp9ddf19ixY5U/f36bbdSsWVPz5s3T1KlT1bdvXzk6OiowMFDjxo1T6dKlH6i/AADg8WNnZ6fnnntOM2bMUJ8+fWz+WF29enUNGzZM8+bN0w8//CBPT09Vr15d06dPV3BwsMLDw1W/fv37rj9fvnz68ssvNXr0aA0cOFC5c+dWt27dbMZqTe122rRpo02bNhkB3N3jqpYuXVqLFi3S5MmTNWjQIFksFlWuXFkLFixQYGBgmnxeq1atSrGmq1Sp0gN9Xo0bN1ahQoU0YMAAxcfHq2HDhho8eLBxIUG5cuW0cOFCffjhh3rnnXdktVpVpkwZzZgxQ0899dQD9XnTpk3atGmTpNsXYeTJk0cVKlTQ1KlT1bRp03su99JLLykuLk6LFy/WokWLlDNnTtWsWVMDBgwwQvcuXbpozJgx6tq1q3FxQWoFBwdr37596tmzp1xdXdWtWzeFhIQY7T169FBUVJTmzp2ruLg4NWjQQKNHj9Ybb7xhzFO9enXVqlVLkyZN0tatW5MNUebs7KzPP/9ckyZNMi74KFGihEaPHm1zVTmAzGGx8pQUAEi1n376SQUKFFDFihWNaYcPH1ZQUJDCwsIeuEgEAAAAAAC4G1faAsAD2Lx5s9asWaP+/fvriSee0Llz5zRz5kyVKFFCderUyezuAQAAAACALIArbQHgAdy8eVMfffSR1q5dq/Pnz8vNzU1169ZVv3795OnpmdndAwAAAAAAWQChLQAAAAAAAACYiF1mdwAAAAAAAAAA8H+EtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIg6Z3QEzu3jxmqzWzO4FsiKLRfLwcOUYA5DlcH5Deks6xpB6fB+RXjjnA8iKOLchvaW2niW0vQ+rVXxBka44xgBkVZzfAPPg+4j0xjEGICvi3IbMxvAIAAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAJjY6tXfKX/+PDavLl06GO0//viDGjasreLFC6p+/Zr64Yc1RtvdyyW9lixZJEm6cOGCunTpoFKliqhaNT8tXrzwX/uzYME8jR070ng/d+4s+ftXUIkShdW1a0dduhRltB0+fEjPP99aJUoUVmCgr6ZMmajExMR7rnvLls1q2LC2ihXzVvPmjbRv394U53v33b569tkWxvvExET16fOGSpQorOeea6kLFy4YbX/9tV+NG9eT1Wq1Wcdzz7XUwYMH/nV/AQAAACAzENoCAGBihw4dUNOmzbV372Hj9eGH0yRJf/65T507v6qXX35V69dvVseOndW1awcj7Lxzmb17Dysk5C0VKVJUzZu3lNVq1WuvvawzZyK0cuUqjRr1gYYNG6RVq769Z1+ioi5q6tTJ6tWrjyTp66+Xa+TIoRo5cqxWr/5REREn9e67/SRJN27cUPv27VSwYCH95z8b9cEHEzVrVpjmzZuT4rpPnDiu9u3bqkWLIG3Y8KsqVKikTp3aKzY21ma+7du3af78uTbT1q79Xlu2/KofflgvV9c8mjp1stE2adI49e37jiwWi80y/fq9q3ff7ZuaHwEAAAAAZDhCWwAATOzQoYMqV66CvL29jVfevG6SpBUrlqpOnXp6/fU3VKJESXXt2l21a9fVt9+ulCSbZW7ejNGcOR9r8uRpypMnr3bv/kM7dmzTzJlz5evrp6efbq6QkLc1Y8ZH9+zLp5/OVoMGTxnbnzZtikJC3tIzz7RW+fIVNHz4KP31134lJCRo69ZfdfnyJU2YMEWlSpVW48ZN1aNHsFasWJriuufM+URPPhmoAQMGqUSJUnr//Q9kZ2enQ4cOGvPExsaqf/8+CgysZrPs4cOHFBgYqDJlyuqpp5royJFDkqQDB/7S8eN/q3nzlsm2V6dOPV24cF6//bYl1T8LAAAAAMgohLYAAJjYoUMHVbJkqRTbXnzxZQ0ZMiLZ9KtXrySbNm7caNWtW1/16zeUdPvKVk9PTxUv/oQxT8WKFbV79x+Ki4tLtnxiYqIWLJinFi1uB6DXrl3V3r271bJlK2OemjVr65dftsne3l6VKlXWZ58tkpOTk816rl27muK+bNmyWS1bPmO8z5Url3bs2KNKlXyNaVOnTlaFChWNfUji4+OjgwcP6tatW9qzZ7cKFy4iSZo8eZzefntAsqtskzRt2kLz56d85S8AAAAAZCZCWwAATMpqtero0cPasGGdatTwV9WqlfX++8ONIQPKlClrE2oeOPCXfvllk+rWbWCznlOnTmrFiqXq2/cdY5qXV35duXJFN27cMKZFREQoPj5eV68mD1b37/9TkZEXVLt2PUnS8ePHJUkXL0aqZcsm8vUto5CQHrpy5bKk21f51q5d11g+JiZGn3/+merWrZ/ivp44cVzOzrnUtWtHVahQUm3aBNmMOXv48CHNmzdHI0d+kGzZoKDWcnV1VbFi3tq0ab1CQt7UoUMHdezYMbVoEZTi9iSpfv2G2rDhp2Tj3QIAAABAZiO0BQDApE6dOqkbN27I0dFJs2d/ptDQ0Vq+/CuNGDEk2bwXL15Uly6vqlq1GsmGA1i4cIGqVPFXQEBVY9qTTwaqQIGCeu+9Abp+/bqOHTuqjz+eLkmKi7MdR1aS9u7draJFixlXzl6/fl2SNHBgP/Xu/bbmzFmggwcPqFev7smWTXpQ2PXr19SnT78U9/X69Wi9//4w1axZS4sXL1ehQoXVrl0rRUdHy2q1ql+/PnrnnfeUP3/+ZMs6Ojrq229/0J49h7R9+24VL/6EcZVtePgO1a9fQ7VrB2rjxvU2y5UtW06XLl3SyZP/pNgnAAAAAMgsDpndAQAAkLIiRYrq4MHjcnPLJ4vFIl/fykpMTFRw8OsaOXKs7O3tJUnnz5/X88+3VmJioubO/Vx2drZ/k1216ht16tTFZlrOnDk1Z85nev3111SyZGF5enopJORNDRv2nlxcXJP1JTIyUu7uHsZ7B4fb2+7d+201a9ZCkjR58jQ99VQdnT59Wo6Ot9cRHx+vkJAe+vHHH/TVV9/I29s7xX11cHDQ0083V7duPY11ValSXmvXrlF0dLQSEhLUsWPn+35eSYHu4cOHdPjwYbVoEaQ6dapq8OBQFS5cWO3bt9POnX8qZ86ckqR8+dz/t28XVLRosfuuGwAAAAAyEqEtAAAmlhQsJilTpqxu3rypS5cuydPTU2fOnFabNreHAPj66zXy9PS0mT8i4pQOHjygZs2SP4zL3z9Av/++V+fOnZOHh4c2bvxJHh4ecnFxSTavxWJRYmKC8d7bu4AkqXTpMsa0UqVKS5JOnjypkiUrKC4uTq+//po2blyvRYuWqVq16vfcT2/vAipV6v/rcnR0VNGiRRUREaENG9Zp9+4/9MQThSTdvhI4ISFBxYsX1ObN2+XjU8RmXZMnj9fbbw/Q5cuXdPjwITVs+JScnZ0lSUeOHDaGlEhMTJSkZCE3AAAAAGQ2fksBAMCk1q9fp7Jli9mMO7tv3x65u7vL09NT169f10svtZGdnZ2+/vp7FShQMNk6du78XYUL+yQLNi9dilJQ0NOKiroob29vOTg46Mcf16pWrbrJ1iFJXl5eioqKMt77+BRRgQIF9eef+4xphw8flMViUbFit69a7devjzZt2qDFi1eoVq06993XgIBA7d+/13gfGxurEyeOq2jRogoLm62ff96m9es3a/36zerUqYuqVPHX+vWbk+3z0aOHdejQQbVs+YwRxiaFswkJ8Tbj10ZFXZQk5c+f8tW/AAAAAJBZuNIWAACTqlatunLmdFbfviHq33+QTpz4WyNGDFVw8FuSpI8+mqTjx//WypWrJUnnzp2TJDk751SePHklSX/9tV9lypRNtu58+dx1/fp1jRw5TG+91V+bN/+sL7/8Qt98832KffH19dM//5xQdHS0XFxcZLFY1KNHsMaNG62iRYvJ09NL77zztlq0CFKBAgW0bNk3Wrx4oSZO/EhPPFHC6Ju9vb08PT2VkJCgyMhI5cuXT46OjurevZdat26uefPmqH79Bpo+/SM5OeVUkybNlDt3bpu+uLnlU86czipRomSyfk6ePEFvvdVfFotFefO66YknSuiLL+Yb4W7JkqWMeffv3ycvr/wqWLDQg/xYAAAAACDdcaUtAAAm5eLiqiVLVioy8qKaNKmvt94KUYcOrykk5E1Jt8eqjYmJUbNmjeTrW9p4DR78rrGOCxcuyM3NLcX1z549X8eP/60GDWpq1qwwzZnzmfz9A1Kct0KFivL2LqAdO7YZ03r16q2uXbsrOLi7goKeVvHiT2jq1LD/9e1bSVL//m/a9K1p0waSbg/b4Otb2lhfQEBVzZ79mWbPnqn69Wvq0KGDWrx4RbLA9n6OHTuqAwf+UlBQK2Pa5MnTNHv2xxo27D199NFM5cqVy2jbtu03NWz4lCwWS6q3AQAAAAAZwWK98z5B2IiMvCY+HaQHi0Xy9HTlGAPwWBk/fowiIk7po4/C7jnP43J+s1qtqlrVT9Onf6IaNWpmdnfwAJKOMaSe2b+PeHw9Lud8AHgQnNuQ3lJbz3KlLQAASJWuXXto48b1unQp6t9nNrmNG9erQIECBLYAAAAATInQFgAApIqHh4feequ/wsKmZXZXHtmHH07Q+PEfZnY3AAAAACBFPIgMAJCuLBaLGDI06+ja9fX7tif9rO3sLKa+nWzVqrWZ3YUsw2q9PdwEAAAAgLRDaAsASDcWi0VWa05FR5PaZhcWixQTI8XHO5s6tEXayZ3bKovlJsEtAAAAkIYIbQEA6cZikaKjLZoxQ7pwgUAnu8iRQ4qL4+edHXh5WRQcbJGrqwjpAQAAgDREaAsASHcXLlh15kxm9wIZxdFRio3N7F4gY1glcSU9AAAAkNZ4EBkAAAAAAAAAmAihLQAAAAAAAACYCKEtAAAAAAAAAJgIoS0AAAAAAAAAmAihLQAAAAAAAACYCKEtAAAAAAAAAJgIoS0AAAAAAAAAmAihLQAAAAAAAACYCKEtAAAAAAAAAJgIoS0AAAAAAAAAmAihLQAAAAAAAACYCKEtAAAAAAAAAJgIoS0AAAAAAAAAmAihLQAAAAAAAACYCKEtAAAAAAAAAJgIoS0AAAAAAAAAmEimhrY//vijypYta/Pq06ePJGn//v16/vnn5efnp7Zt22rfvn02y65atUqNGzeWn5+fgoODFRUVZbRZrVZNnDhRNWrUULVq1TR+/HglJiZm6L4BAAAge6CmBQAAQFrL1ND2yJEjatiwoTZv3my8Ro0apRs3bqh79+4KDAzUihUr5O/vrx49eujGjRuSpD179mjw4MEKCQnRkiVLdPXqVQ0aNMhY77x587Rq1SpNnz5dU6dO1Xfffad58+Zl1m4CAAAgC6OmBQAAQFrL1ND26NGjKlOmjLy8vIxXnjx5tGbNGjk5Oemdd95RyZIlNXjwYOXOnVs//PCDJOmLL75Q8+bN9eyzz6pcuXIaP368Nm3apJMnT0qSFixYoD59+igwMFA1atRQ//79tXDhwszcVQAAAGRR1LQAAABIa5ke2hYvXjzZ9N27dysgIEAWi0WSZLFY9OSTT2rXrl1Ge2BgoDF/wYIFVahQIe3evVvnzp3TmTNnVLVqVaM9ICBAEREROn/+fLruDwAAALIfaloAAACktUwLba1Wq/7++29t3rxZTZs2VePGjTVx4kTFxsbqwoULyp8/v838Hh4eOnv2rCTp/Pnz92y/cOGCJNm0e3p6SpKxPAAAAJAWqGkBAACQHhwya8OnT59WTEyMHB0dNWXKFJ06dUqjRo3SzZs3jel3cnR0VGxsrCTp5s2b92y/efOm8f7ONknG8qn1v4sigDSXdGxxjCGrs1g4zoGsLul7nlHfdbOdU6hpkZ1R0wLIiji3Ib2l9tjKtNC2cOHC2rZtm/LmzSuLxaLy5csrMTFRAwYMULVq1ZIVo7GxscqZM6ckycnJKcV2Z2dnm2LWycnJ+LckOTs7P1AfPTxcH2rfgNTiGEN2EBMj5cgh3ZVLIItzdMy0EgMZKEcOycFBcnd3yeyuZBpqWoBjDEDWxLkNmS1Tf6Nyc3OzeV+yZEndunVLXl5eioyMtGmLjIw0bg/z9vZOsd3Ly0ve3t6SpAsXLsjHx8f4tyR5eXk9UP8uXrwmq/WBFgFSxWK5/R8AxxiyOjs7i+LjnRUXZ9UDXhiGx5ijo4NiY+MzuxvIAHFxUny8RVFRMUpMzJj/0JL+DzUTalpkV9S0ALIizm1Ib6mtZzNtTNtffvlF1atXV0xMjDHtr7/+kpubmwICAvTHH3/I+r9vh9Vq1c6dO+Xn5ydJ8vPzU3h4uLHcmTNndObMGfn5+cnb21uFChWyaQ8PD1ehQoWSjRn2b6xWXrzS78Uxxis7vQBkXdn9nEJNyyu7vzjGePHilRVfnNt4pfcrNTIttPX395eTk5OGDBmiY8eOadOmTRo/fry6deumZs2a6erVqxo9erSOHDmi0aNHKyYmRs2bN5cktW/fXt98842WLl2qAwcO6J133lGDBg1UpEgRo33ixInatm2btm3bpkmTJqljx46ZtasAAADIoqhpAQAAkB4sVmtq8920d/jwYY0ZM0a7du1S7ty59dJLLyk4OFgWi0V79uzR8OHDdfToUZUtW1YjRoxQhQoVjGVXrFihqVOn6sqVK6pdu7bef/995cuXT5KUkJCg8ePHa8WKFbK3t1e7du3Ur18/WR5wFOnISC6FR/qwWCRPT1eOMWR5dnYWXbvmrNBQq86cyezeIKMwPEL2UbCgFBpqkatrxg6P4OlpruERqGmRXVHTAsiKOLchvaW2ns3U0Nbs+IIivfCfALILQtvsidA2+yC0fTxQbyC9UNMCyIo4tyG9pbaezbThEQAAAAAAAAAAyRHaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgImYJrTt3r27Bg4caLzfv3+/nn/+efn5+alt27bat2+fzfyrVq1S48aN5efnp+DgYEVFRRltVqtVEydOVI0aNVStWjWNHz9eiYmJGbYvAAAAyH6oZwEAAJBWTBHarl69Wps2bTLe37hxQ927d1dgYKBWrFghf39/9ejRQzdu3JAk7dmzR4MHD1ZISIiWLFmiq1evatCgQcby8+bN06pVqzR9+nRNnTpV3333nebNm5fh+wUAAIDsgXoWAAAAaSnTQ9vLly9r/Pjx8vX1NaatWbNGTk5Oeuedd1SyZEkNHjxYuXPn1g8//CBJ+uKLL9S8eXM9++yzKleunMaPH69Nmzbp5MmTkqQFCxaoT58+CgwMVI0aNdS/f38tXLgwU/YPAAAAWRv1LAAAANJapoe248aNU+vWrVWqVClj2u7duxUQECCLxSJJslgsevLJJ7Vr1y6jPTAw0Ji/YMGCKlSokHbv3q1z587pzJkzqlq1qtEeEBCgiIgInT9/PmN2CgAAANkG9SwAAADSWqaGtlu3btXvv/+uXr162Uy/cOGC8ufPbzPNw8NDZ8+elSSdP3/+nu0XLlyQJJt2T09PSTKWBwAAANIC9SwAAADSg0NmbfjWrVsaPny4hg0bppw5c9q0xcTEyNHR0Waao6OjYmNjJUk3b968Z/vNmzeN93e2STKWT63/XRgBpLmkY4tjDFmdxcJxDmR1Sd/zjPqum+mc8jjUs5K5PjNkLdS0ALIizm1Ib6k9tjIttJ0+fboqVaqkunXrJmtzcnJKVpDGxsYaxfC92p2dnW0KWicnJ+PfkuTs7PxAffTwcH2g+YEHxTGG7CAmRsqRQ7orm0AW5+iYaSUGMlCOHJKDg+Tu7pLZXckUj0M9K1FvIP1xjAHIiji3IbNl2m9Uq1evVmRkpPz9/SX9vxBdu3atgoKCFBkZaTN/ZGSkcYuYt7d3iu1eXl7y9vaWdPuWNB8fH+PfkuTl5fVAfbx48Zqs1gfcMSAVLJbb/wFwjCGrs7OzKD7eWXFxVj3ExWF4TDk6Oig2Nj6zu4EMEBcnxcdbFBUVo8TEjPkPLen/UDN4HOpZiZoW6YeaFkBWxLkN6S219Wymhbaff/654uP//wvdxIkTJUn9+/fXjh07NHv2bFmtVlksFlmtVu3cuVM9e/aUJPn5+Sk8PFxt2rSRJJ05c0ZnzpyRn5+fvL29VahQIYWHhxtFbnh4uAoVKpRs3LB/Y7WKLyjSFccYsjqOcSDrS/qeZ8fv+uNQz0rZ9+eDjMMxBiAr4tyGzJZpoW3hwoVt3ufOnVuSVKxYMXl4eGjSpEkaPXq0XnrpJS1evFgxMTFq3ry5JKl9+/bq0KGDqlSpIl9fX40ePVoNGjRQkSJFjPaJEyeqQIECkqRJkyapS5cuGbh3AAAAyOqoZwEAAJBeTDngnIuLiz755BMNHz5cX331lcqWLatZs2YpV65ckiR/f3+NHDlSU6dO1ZUrV1S7dm29//77xvJdu3bVxYsXFRISInt7e7Vr106vvfZaJu0NAAAAshvqWQAAADwKi9XKxd73EhnJ+CVIHxaL5OnpyjGGLM/OzqJr15wVGmrVmTOZ3RtkFMa0zT4KFpRCQy1ydc3YMW09Pc0xpu3jgnoD6YWaFkBWxLkN6S219axdBvQFAAAAAAAAAJBKhLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtgAAAAAAAABgIoS2AAAAAAAAAGAihLYAAAAAAAAAYCKEtsgyjh07qhdeeFbFixeUv38FTZ/+0T3nK1o0/z3XEx6+QwUKuOmff04Y0y5fvqQ33uimMmWKqnLlsho1KlSJiYn37c+CBfM0duxISdL169fVt29vlS1bTKVLF1Xfvn0UHR0tSVq8eKHy58+T7OXtnfee6545c7r8/SuoWDFvvfDCszp27IhN+9y5s+TvX0ElShRW164ddelSlNE2evQIlSpVRI0b19PRo4eN6RcuXFC1an6KiYmxWdcbb3TTxo3r77uvAAAAAAAASDuEtsgSEhMT9corz8vDw1Pr1/+iCRM+1IcfTtDy5V/ZzBcRcUqvvvqCbt68meJ64uLi1Ldvn2SB7Lvv9tW5c2f17bdrFRY2W4sXL9SsWWH37E9U1EVNnTpZvXr1kSQNHTpQu3b9oa+++lrLl3+rnTvD1bdvX0lS69ZttHfvYeP1xx/79cQTJdS9+xsprnvZsiWaNGmcJkz4UBs2/Cp3dw+9+uqLslqtkqSvv16ukSOHauTIsVq9+kdFRJzUwIH9JEn79u3Vp5/O1sqVqxQQEKj33w811hsWNlVdu3aXs7OzzfYGDBikIUPeVWxs7D33FwAAAAAAAGmH0BZZwoUL51WpUmVNmPChSpQopcaNm6pu3fratm2rMc+aNavUpEk9OTo63XM906dPkaura7Lp69b9qJ49g1WuXHnVqVNPbdo8r19+2XTP9Xz66Ww1aPCU8uZ1kyTlyJFDY8dOlJ+fvypXrqKXX35VmzdvliQ5OzvL29vbeC1btkRWq1VDhoxIcd1Xr17VsGEj1bhxU5UoUUq9e7+tI0cOKzIyUpI0bdoUhYS8pWeeaa3y5Sto+PBR+uuv/UpISNCRI4dUtmw5+fr6qWnTFjpy5JAk6eLFi1qz5jt17Ngl2fZKlCgpH58i+vrr5ffcXwAAAAAAAKQdQltkCd7eBTR79ny5uLjKarVq27bf9Ntvv6p27brGPOvWrdW77w7R6NHjUlzH0aOH9emnszVixOhkbfnyuWvZsiW6ceOGzp49ow0b1snXt3KK60lMTNSCBfPUokVLY9q4cZNVvXoNSdI//5zQihVL1aBBg2TLXroUpWnTpmjo0BFycko5XO7S5XV17NhZknT16hV9+ulslStXXp6enrp27ar27t2tli1bGfPXrFlbP/+8Tfb29ipc2EcnThzX1atXtGfPLhUu7CPp9lW2nTt3S3aVbZKmTVto/vy5KbYBAAAAAAAgbTlkdgeAtBYQUEmnTp3U0083U1BQa2P65MnTJEm//vpLsmWsVqv69XtTAwYMkpdX8vFux4+fpODg7ipRopASExNVr15D9e8/KMXt79//pyIjL6h27XrJ2kJCeuirr75U0aLFNGzYsGTt8+fPVYECBfTMM8/+634uWvS53norWE5OTlqyZKUsFouOHz8uSbp4MVItWzbRP/+cUP36DTV69DjlzeumqlWrq3btOipTppjy5cunRYuWKSrqolat+kYbN26957bq12+oQYP668qVy8bVwwAAAAAAAEgfXGmLLOfTTz/XF18s0b59ezV06MBULbNw4QLFxcWpQ4fXUmw/cuSw/Pz8tWrVfzRv3kIdOLBf06Z9mOK8e/fuVtGixVK8UrZ377e1Zs06+fgUUfPmzW3GzrVarVq4cIG6du2Rqj7Xq9dAP/30i159tZM6dmyvEyeO6/r165KkgQP7qXfvtzVnzgIdPHhAwcHdjeVmzZqvP/88qr17D8vfP0AzZ05X587ddOZMhJo1a6hq1fz01Vdf2myrePEnlCNHDu3btzdVfQMAAAAAAMDD40pbZDlVqjwpSbp165beeKObQkNHy9HR8Z7znzt3TmPGjNTy5d/JYrEkaz927IiGDx+sXbv+krd3AUlSTMwNvfNOX/Xu/bYcHGy/RpGRkXJ390hxW2XLlpMkzZ49X76+ZbR166+qVev2EA67du3U6dMReu65tqnaTx+fIvLxKaIxYypry5bNWrJkkRo1aizpdjjcrFkLSbevMH7qqTo6e/aMChQoKEny8Ljdv0uXovTdd19rw4Yt6tz5FT33XDs988yzatCgpurVa2DMb2dnp7x53RQZeSFVfQMAAAAAAMDD40pbZAnnz5/XmjWrbKaVKVNOsbGxunbt2n2X3bBhnaKiLqp586dUvHhB1atXXZJUr151TZkyUXv37pG7u4cR2EqSr6+foqOv6dKlS8nWZ7FYlJiYYLyPjY3Vd999o2vXrhrT8ufPLw8PD128eNGYtn79OtWsWVtubvnu29/Nm3/WkSOHbbZXunRZRUVdNPpYunQZo71UqdKSpIiIU8nW9fHH09WpU1c5Oztr+/ZtatiwsQoVKqwSJUrqjz922sybmJgoOztOGQAAAAAAAOmNBAZZwj//HFfnzq/ozJnTxrTdu/+Qp6encVXpvQQFtdKWLeFav36z1q/frEWLlkmSFi1apk6dusjbu6Cioi7qwoX/X2V6+PAh5c7tIk9Pz2Tr8/LyUlRUlPHezs5OvXv31I8/rjWmnTp1UpGRkSpTpqwxbefO31W1avV/3ddp0z7UzJnTjfcJCQnat2+PSpcuKx+fIipQoKD+/HPfHX09KIvFIh+fojbruXz5kr75ZqVee62r0c+k4Rri4xNktVqNeRMTE3X58iV5eXn/a/8AAAAAAADwaBgeAVmCv3+A/Pyq6M03e+n99z/QyZMnNGLEUL31Vv9/XdbFxVUuLq7G+6ThDnx8iihfPncFBlZVmTLlFBLSXSNGjFFU1EWNGDFEXbt2T3E4BV9fP/3zzwlFR0fLxcVFDg4O6tixs8aMGalChXzk7JxTgwb1V+vWrVWuXHklZaMHDvyldu1eTLa+hIQERUZGKl++fHJ0dFTnzq+rW7eOqlWrtvz8/DVz5jTdvHlTL774siwWi3r0CNa4caNVtGgxeXp66Z133lbz5kHy9rYNXD/+eIY6duwiZ2dnSbeHlfjyyy/UrFkLHT58UH5+VYx5Dx06KEmqWLHiv36eAAAAAAAAeDSEtsgS7O3ttWDBYg0c2F8tWjRWrly59PrrPfX662888rodHBz05ZfLNHjwu2rVqqly53bR88+/pAEDBqU4f4UKFeXtXUA7dmxTw4ZPSZIGDx4ui8Wibt066saNG2rZ8hnNmjVTsbH/X+7ChfPKm9ct2foiIk4pMNBXK1euVu3addWsWQuNH/+hJkwYq9OnIxQYWE1fffW1XFxcJEm9evXWrVs3FRzcXdevX1ezZs01frztQ9OuXLmsr79ervXrfzWmvf/+WPXo0VlffbVII0eOVeHCPkbbtm1bVbVqdbm65nnYjxEAAAAAAACpZLHeeQ80bERGXhOfDh7G+PFjFBFxSh99FJZiu8UieXq6PjbH2HPPtdTLL3fQ88+/lNldwWPGzs6ia9ecFRpq1Zkzmd0bZBRHRwfFxsZndjeQAQoWlEJDLXJ1jVFiYsb8h5b0fyhS73GpN/D4edxqWgBIDc5tSG+prWcZ0xZIB1279tDGjet16VLUv89scocPH9KpUyf17LNtM7srAAAAAAAA2QKhLZAOPDw89NZb/RUWNi2zu/LIJk4cq3HjJilHjhyZ3RUAAAAAAIBsgTFtTcJisSiFZ1rhMda16+v3bEv6WdvZWUx/u8Xs2fMzuwtZhtUqMSINAAAAAAD4N4S2JmCxWGS15lR0NKltdmGxSDExUny8s+lDW6Sd3LmtslhuEtwCAAAAAID7IrQ1AYtFio62aMYM6cIFwpzsIkcOKS6On3d24eVlUXCwRa6uIqgHAAAAAAD3RWhrIhcu8HT17MTRUYqNzexeIONYJXE1PQAAAAAA+Hc8iAwAAAAAAAAATCTNQ9uoqKi0XiUAAACQYahnAQAAkNkeKrQtX758isVsRESEnnrqqUfuFAAAAJCeqGcBAABgZqke0/brr7/WihUrJElWq1XBwcHKkSOHzTznz5+Xl5dX2vYQAAAASAPUswAAAHhcpDq0bdKkiU6dOiVJ2r59u6pUqaLcuXPbzJMrVy41adIkbXsIAAAApAHqWQAAADwuUh3a5s6dWyEhIZKkwoULq0WLFnJycnqkjZ84cUIjR47Uzp07lTdvXr366qvq1q2bJOnkyZMaOnSodu3apUKFCum9995TnTp1jGW3bNmiMWPG6OTJk/Lz89Po0aNVpEgRo33+/PmaO3euoqOj1bx5cw0dOlTOzs6P1F8AAAA8vtKjnpWoaQEAAJD2Uh3a3um5557TiRMntG/fPsXFxSVrf/bZZ/91HYmJierevbt8fX21cuVKnThxQn379pW3t7eCgoIUHBysMmXKaPny5Vq3bp1CQkK0Zs0aFSpUSKdPn1ZwcLB69+6tunXrasaMGerVq5e+/fZbWSwWrV27VtOnT9eECRPk4eGhQYMGacKECRo2bNjD7C4AAACymLSoZyVqWgAAAKSPhwpt58yZo4kTJypv3rzJbimzWCypKnIjIyNVvnx5hYaGysXFRcWLF1fNmjUVHh4uT09PnTx5UosXL1auXLlUsmRJbd26VcuXL1fv3r21dOlSVapUSV26dJEkjR07VrVr19b27dtVvXp1LViwQJ06dVLDhg0lSSNGjFDXrl01YMAArkwAAABAmtSzEjUtAAAA0sdDhbaffvqpBgwYoK5duz70hvPnz68pU6ZIuv0giJ07d2rHjh0aPny4du/erQoVKihXrlzG/AEBAdq1a5ckaffu3QoMDDTanJ2dVbFiRe3atUuBgYHau3evceubJFWpUkVxcXE6cOCA/P39H7rPAAAAyBrSop6VqGkBAACQPh4qtL1165aefvrpNOtEo0aNdPr0aTVs2FBNmzbVmDFjlD9/fpt5PDw8dPbsWUnShQsX7tl+9epV3bp1y6bdwcFBbm5uxvKpZbE85A49IIsl47YFIPMkfdez0/c9u+0vkB1l9LktrbaT1vWsRE2L7Cfp2OIYA5CVcG5DekvtsfVQoe0zzzyjRYsW6Z133pElDY7iqVOnKjIyUqGhoRo7dqxiYmLk6OhoM4+jo6NiY2Ml6b7tN2/eNN7fa/nU8vBwfdBdeWgxMVKOHNJd3UYW5+j4UF9BPIZy5JAcHCR3d5fM7kqG4/yWPXF+yx4e53NbWtezEjUtsi+OMQBZEec2ZLaH+o0qOjpay5Yt06pVq+Tj46McOXLYtC9YsOCB1ufr6yvp9hUP/fv3V9u2bRUTE2MzT2xsrHLmzClJcnJySlasxsbGKk+ePMYTgFNqf9Cxvy5evCar9YEWeSh2dhbFxzsrLs6qB6zB8RhzdHRQbGx8ZncDGSQuToqPtygqKkaJiRlwYjEJzm/ZE+e37CMzzm0WS9r8EpXW9axETYvsJ+n7yDEGICvh3Ib0ltp69qFC2+LFi6tnz54Ps6ghMjJSu3btUuPGjY1ppUqVUlxcnLy8vHTs2LFk8yfdHubt7a3IyMhk7eXLl5ebm5ucnJwUGRmpkiVLSpLi4+N1+fJleXl5PVAfrVZlyBc0o7YDIHMlfdez0/c9u+0vkB09rue2tKhnJWpaQOIYA5A1cW5DZnuo0PbOByI8rFOnTikkJESbNm2St7e3JGnfvn1yd3dXQECAPv30U928edO4EiE8PFwBAQGSJD8/P4WHhxvriomJ0f79+xUSEiI7Ozv5+voqPDxc1atXlyTt2rVLDg4OKleu3CP3GwAAAI+/tKhnJWpaAAAApI+HCm0HDRp03/axY8f+6zp8fX1VsWJFvffeexo0aJAiIiI0YcIE9ezZU9WqVVPBggU1aNAg9erVSxs2bNCePXuM9bZt21Zz587VrFmz1LBhQ82YMUM+Pj5GQfvyyy9r2LBhKlOmjPLnz6/Q0FC98MILD3wrGQAAALKmtKhnJWpaAAAApA+7tFhJfHy8/v77b61Zs0bu7u6pWsbe3l5hYWFydnbWiy++qMGDB6tDhw7q2LGj0XbhwgW1adNG3377rWbMmKFChQpJknx8fDRt2jQtX75c7dq10+XLlzVjxgzjIRItW7ZUjx49NGzYMHXp0kWVK1fWgAED0mJXAQAAkAU9TD0rUdMCAAAgfVis1rQboWPOnDk6dOiQxo8fn1arzFSRkRn3ILJr15wVGmrVmTPpvz2YAw/qyV4KFpRCQy1ydc1+DyLj/Jb9cH7LPjLj3GaxSJ6e6fc056xWz0oZV9Mi+0n6PnKMAchKOLchvaW2nk2TK22TNGvWTD/++GNarhIAAADIMNSzAAAAMIM0C21v3Lihr776Svny5UurVQIAAAAZhnoWAAAAZvFQDyIrV66cMdbWnZycnDRq1KhH7hQAAACQnqhnAQAAYGYPFdouWLDA5r3FYlGOHDlUqlQpubi4pEnHAAAAgPRCPQsAAAAze6jQtlq1apKk48eP6+jRo0pMTNQTTzxBgQsAAIDHAvUsAAAAzOyhQturV69q0KBB+umnn5Q3b14lJCTo+vXrqlq1qmbMmCFX1/R7oi8AAADwqKhnAQAAYGYP9SCyUaNG6ezZs1qzZo22bdum33//Xd99951u3LihsWPHpnUfAQAAgDRFPQsAAAAze6jQdv369QoNDVWJEiWMaaVKldKwYcP0008/pVnnAAAAgPRAPQsAAAAze6jQ1snJSXZ2yRe1WCxKSEh45E4BAAAA6Yl6FgAAAGb2UKFto0aNNGLECP3zzz/GtOPHj2vUqFGqX79+mnUOAAAASA/UswAAADCzh3oQ2YABAxQcHKymTZsqT548kqQrV66oXr16Gjp0aJp2EAAAAEhr1LMAAAAwswcObU+cOKFChQrp888/18GDB3X06FE5OTmpePHiKlmyZHr0EQAAAEgz1LMAAAAwu1QPj2C1WjVq1Cg1b95cf/zxhySpbNmyatGihZYvX66goCB98MEHslqt6dZZAAAA4GFRzwIAAOBxkerQdsGCBVqzZo1mzJihatWq2bSFhYVpxowZWrlypb788ss07yQAAADwqKhnAQAA8LhIdWj71VdfaejQoWrYsGGK7Y0aNVL//v0pcgEAAGBK1LMAAAB4XKQ6tI2IiFDlypXvO0+NGjV08uTJR+4UAAAAkNaoZwEAAPC4SHVo6+HhoYiIiPvOc/bsWbm5uT1qnwAAAIA0Rz0LAACAx0WqQ9smTZpo2rRpiouLS7E9Pj5e06dPV506ddKscwAAAEBaoZ4FAADA48IhtTP26tVL7dq1U5s2bdShQwdVqlRJrq6uunLliv7880998cUXun79usaPH5+e/QUAAAAeCvUsAAAAHhepDm3z5Mmjr776ShMnTtQHH3ygmJgYSZLVapWrq6tatGih3r17y9PTM906CwAAADws6lkAAAA8LlId2kqSm5ubRo0apWHDhunkyZO6evWq3NzcVLRoUdnb26dXHwEAAIA0QT0LAACAx8EDhbZJHB0dVbJkybTuCwAAAJAhqGcBAABgZql+EBkAAAAAAAAAIP0R2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiWRqaHvu3Dn16dNH1apVU926dTV27FjdunVLknTy5Em99tprqlKlilq0aKHNmzfbLLtlyxYFBQXJz89PHTt21MmTJ23a58+fr7p168rf31/vvfeeYmJiMmy/AAAAkD1QzwIAACA9ZFpoa7Va1adPH8XExGjhwoX68MMPtWHDBk2ZMkVWq1XBwcHy9PTU8uXL1bp1a4WEhOj06dOSpNOnTys4OFht2rTRsmXL5O7url69eslqtUqS1q5dq+nTp2vkyJH67LPPtHv3bk2YMCGzdhUAAABZEPUsAAAA0kumhbbHjh3Trl27NHbsWJUuXVqBgYHq06ePVq1apd9++00nT57UyJEjVbJkSfXo0UNVqlTR8uXLJUlLly5VpUqV1KVLF5UuXVpjx45VRESEtm/fLklasGCBOnXqpIYNG6py5coaMWKEli9fztUJAAAASDPUswAAAEgvmRbaenl5ac6cOfL09LSZHh0drd27d6tChQrKlSuXMT0gIEC7du2SJO3evVuBgYFGm7OzsypWrKhdu3YpISFBe/futWmvUqWK4uLidODAgfTdKQAAAGQb1LMAAABILw6ZteE8efKobt26xvvExER98cUXqlGjhi5cuKD8+fPbzO/h4aGzZ89K0n3br169qlu3btm0Ozg4yM3NzVg+tSyWB92rh2OxZNy2AGSepO96dvq+Z7f9BbKjjD63memc8jjUs5K5PjNkLUnHFscYgKyEcxvSW2qPrUwLbe82YcIE7d+/X8uWLdP8+fPl6Oho0+7o6KjY2FhJUkxMzD3bb968aby/1/Kp5eHh+qC78dBiYqQcOaS7uo0sztHRNF9BpLMcOSQHB8nd3SWzu5LhOL9lT5zfsofsfG5LiRnrWSlja1pkTxxjALIizm3IbKb4jWrChAn67LPP9OGHH6pMmTJycnLS5cuXbeaJjY1Vzpw5JUlOTk7JCtbY2FjlyZNHTk5Oxvu7252dnR+oXxcvXtP/ngWRruzsLIqPd1ZcnFUPUYfjMeXo6KDY2PjM7gYySFycFB9vUVRUjBITM+DEYhKc37Inzm/ZR2ac2ywWc/4SZdZ6Vsq4mhbZT9L3kWMMQFbCuQ3pLbX1bKaHtu+//76+/PJLTZgwQU2bNpUkeXt768iRIzbzRUZGGreIeXt7KzIyMll7+fLl5ebmJicnJ0VGRqpkyZKSpPj4eF2+fFleXl4P1DerVRnyBc2o7QDIXEnf9ez0fc9u+wtkR9nx3HY3M9ezEj8fpD+OMQBZEec2ZLZMexCZJE2fPl2LFy/W5MmT1bJlS2O6n5+f/vzzT+PWMEkKDw+Xn5+f0R4eHm60xcTEaP/+/fLz85OdnZ18fX1t2nft2iUHBweVK1cuA/YKAAAA2QX1LAAAANJDpoW2R48eVVhYmF5//XUFBATowoULxqtatWoqWLCgBg0apMOHD2vWrFnas2eP2rVrJ0lq27atdu7cqVmzZunw4cMaNGiQfHx8VL16dUnSyy+/rLlz52rdunXas2ePQkND9cILLzzU7WQAAABASqhnAQAAkF4ybXiEn376SQkJCZo5c6Zmzpxp03bw4EGFhYVp8ODBatOmjYoVK6YZM2aoUKFCkiQfHx9NmzZNY8aM0YwZM+Tv768ZM2bI8r/Hr7Vs2VIREREaNmyYYmNj9fTTT2vAgAEZvo8AAADIuqhnAQAAkF4sVisjdNxLZGTGPYjs2jVnhYZadeZM+m8P5sCDerKXggWl0FCLXF2z34PIOL9lP5zfso/MOLdZLJKnp/keRGZmGVXTIvtJ+j5yjAHISji3Ib2ltp7N1DFtAQAAAAAAAAC2CG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADAREwR2sbGxiooKEjbtm0zpp08eVKvvfaaqlSpohYtWmjz5s02y2zZskVBQUHy8/NTx44ddfLkSZv2+fPnq27duvL399d7772nmJiYDNkXAAAAZE/UtAAAAEgrmR7a3rp1S3379tXhw4eNaVarVcHBwfL09NTy5cvVunVrhYSE6PTp05Kk06dPKzg4WG3atNGyZcvk7u6uXr16yWq1SpLWrl2r6dOna+TIkfrss8+0e/duTZgwIVP2DwAAAFkfNS0AAADSUqaGtkeOHNELL7ygf/75x2b6b7/9ppMnT2rkyJEqWbKkevTooSpVqmj58uWSpKVLl6pSpUrq0qWLSpcurbFjxyoiIkLbt2+XJC1YsECdOnVSw4YNVblyZY0YMULLly/nygQAAACkOWpaAAAApLVMDW23b9+u6tWra8mSJTbTd+/erQoVKihXrlzGtICAAO3atctoDwwMNNqcnZ1VsWJF7dq1SwkJCdq7d69Ne5UqVRQXF6cDBw6k7w4BAAAg26GmBQAAQFpzyMyNv/zyyylOv3DhgvLnz28zzcPDQ2fPnv3X9qtXr+rWrVs27Q4ODnJzczOWBwAAANIKNS0AAADSWqaGtvcSExMjR0dHm2mOjo6KjY391/abN28a7++1fGpZLA/a84djsWTctgBknqTvenb6vme3/QWyo4w+tz1O55TsVtMi+0k6tjjGAGQlnNuQ3lJ7bJkytHVyctLly5dtpsXGxipnzpxG+93FamxsrPLkySMnJyfj/d3tzs7OD9QPDw/XB+z5w4uJkXLkkO6qy5HFOTqa8iuIdJAjh+TgILm7u2R2VzIc57fsifNb9pCdz22pkR1rWmRPHGMAsiLObchspvyNytvbW0eOHLGZFhkZadwe5u3trcjIyGTt5cuXl5ubm5ycnBQZGamSJUtKkuLj43X58mV5eXk9UD8uXrym/z28N13Z2VkUH++suDirHvDCCTzGHB0dFBsbn9ndQAaJi5Pi4y2KiopRYmIGnFhMgvNb9sT5LfvIjHObxfL4/BKV3WpaZD9J30eOMQBZCec2pLfU1rOmDG39/Pw0a9Ys3bx507gSITw8XAEBAUZ7eHi4MX9MTIz279+vkJAQ2dnZydfXV+Hh4apevbokadeuXXJwcFC5cuUeqB9WqzLkC5pR2wGQuZK+69np+57d9hfIjrLjuS21sltNi+yLYwxAVsS5DZnNLrM7kJJq1aqpYMGCGjRokA4fPqxZs2Zpz549ateunSSpbdu22rlzp2bNmqXDhw9r0KBB8vHxMQral19+WXPnztW6deu0Z88ehYaG6oUXXnjgW8kAAACAh0VNCwAAgIdlytDW3t5eYWFhunDhgtq0aaNvv/1WM2bMUKFChSRJPj4+mjZtmpYvX6527drp8uXLmjFjhiz/G8m3ZcuW6tGjh4YNG6YuXbqocuXKGjBgQGbuEgAAALIZaloAAAA8LIvVysXe9xIZmXFj2l675qzQUKvOnEn/7cEcGPMxeylYUAoNtcjVNfuNacv5Lfvh/JZ9ZMa5zWKRPD0fjzFtzSKjalpkP0nfR44xAFkJ5zakt9TWs6a80hYAAAAAAAAAsitCWwAAAAAAAAAwEUJbAAAAAAAAADARQlsAAAAAAAAAMBFCWwAAAAAAAAAwEUJbAAAAAAAAADARQlsAAAAAAAAAMBFCWwAAAAAAAAAwEUJbAAAAAAAAADARQlsAAAAAAAAAMBFCWwAAAAAAAAAwEUJbAAAAAAAAADARQlsAAAAAAAAAMBFCWwAAAAAAAAAwEUJbAAAAAAAAADARQlsAAAAAAAAAMBFCWwAAAAAAAGSY1au/U/78eWxeXbp0MNo3bPhJDRrUUvHiBdW2bSsdOXLYZvlSpYokWz46Ovqe2ztw4C8991xL432DBrWSLf/XX/slSdHR0Xr99ddVrtwT8vMrp6lTP7zvvgwe/E6ydc2d+4nRvmLFUlWtWlnFinmrU6eXdfHiRaNt1apvValSaVWpUl5r135vs95mzRpq797dNtM+/3y+xowZed/+IOtwyOwOAAAAAAAAIPs4dOiAmjZtrokTpxrTcuZ0knQ7YH3llefVp09ftWv3ohYuXKA2bYK0ZUu4XFxcdObMaV29ekXbt++Ws3MuY/ncuXPfc3sDB/ZT//4DJUkJCQk6duyIvvnme5UoUcqYx8PDQ5LUt29v7du3R5999qUSExMVHNxdOXLk0BtvhKS47oMHD2rIkFC9+OIrxjRXV1dJ0s6dv+vtt0M0fvyHqlSpsgYPfkd9+vTUwoVLlZCQoP79+2jUqHFKTEzUm2++ob/++lsWi0Xr1q1V/vwF5OvrZ7Ot9u1fVf36NfTii+1VsmTpVH3WeHxxpS0AAAAAAAAyzKFDB1WuXAV5e3sbr7x53SRJ8+fPUdWq1TVw4BCVKlVaw4aNVJ48ebR8+VfGst7eBVS8+BM2y1sslhS3tXXrrzp//pzq1KknSTpx4rhiY2Pl7x9gs7yDg4MuXryolSuX65NPPlH16jVUo0YtDR06QmFhU1NctyQdPnxQvr5+NuvKlet2mDx37iy1avWcXnzxZVWsWEkzZszSunX/0YkTx3Xx4kVFRUWpVavn1Lp1G0VFRSkyMlKSNGnSOA0YMDDZthwcHPTii69o2rQpD/vR4zFCaAsAAAAAAIAMc+jQQZUsWSrFthMnjuvJJwON9xaLReXLV9Tvv2//37IH7rlsSubPn6PmzYNstl24sI9y5syZwrb/liRVr17dmFahQiWdO3dW//xzItn8165d1Zkzp+/Zn/DwHapZs7bxvnBhH/n4FFF4+A55eHgoV65c2rNnl3bv3qVcuXLL3d1d69f/KC+v/Mmusk3SrFkLrVy5TFeuXE7V/uPxRWgLAAAAAACADGG1WnX06GFt2LBONWr4q2rVynr//eGKjY2VJHl55deZM6dtlomIOKWoqNtjwR46dEgxMTf07LMtVKlSabVv31ZHjx5Otp2kbW3cuF716zc0ph06dFA5cuTQK688r4oVS6l16+baufN3Y9u3txdhs21JxvbvdOjQQVksFk2ZMlF+fuXUoEEtLV680Gg/d+6cChQoYLOMl5eXTp8+LXt7ew0dOkKtWjVTmzYtNXLkGNnb22vixHEaMGDQPT+/MmXKys0tn7Zu3XLPeZA1ENoCAAAAAAAgQ5w6dVI3btyQo6OTZs/+TKGho7V8+VcaMWKIJOnZZ9vou+++1n/+873i4+O1ePFC7dq10wh1jxw5pEuXLunttwdowYIvlTOns9q2baXo6GvJtvXPPyd06dIllSlT1ph25MghXblyWa+80klffrlMZcqUU9u2rRQRcUpFihRVYGBVvfnmm7p0KUrnzp3ThAljJUmxsXHJ1n/48CFZLBaVKlVGixYt06uvdlT//m9q9ervJEkxMbf3806Ojk6Kjb0lSeratYcOHTqhAweOq2PHztqw4Sd5enqqRIlS6tatk/z9K2jo0EGyWq026yhTpqz27Nn1kD8BPC54EBkAAAAAAAAyRJEiRXXw4HG5ueWTxWKRr2/l/z3w63WNHDlWjRo1Uf/+A9WlSwfFx8erdu16euGF9rp69aokafHiFYqLi5OLi4skaebMOfL3L6+1a79X27Yv2Gzr4sXbY8S6u3sY0yZPnqaYmBtydc0jSRo/3k/bt/+mpUsX6623+mvGjFnq3v01lS37hPLkyavBg4fr99+3Gw8Xu9OLL76spk2bK18+d0lSxYqVdPToEc2fP0ctWz6jnDlzGgFtktjYWzYPUHNx+f96J00apzFjxmvu3FmKj4/Xli3hat26mVat+lbPPNPamM/d3V2RkRce/MPHY4UrbQEAAAAAAJBh8uVzt3lwWJkyZXXz5k1dunRJkvT22wN09GiE9u49rOXLv1V0dLSKFCkqSXJycjICW0nKmTOnihYtpjNnziTbTtI2EhISjGkODg5GYJs0T+nSZYwhGUqUKKldu3bpzz+PaN++w6pZs7bs7Ozk4+OT4vqTAtskpUuX1dmzt/tSoEBBnT9/3qb9/Pnz8vb2TrauTZs2KF++fKpcuYp27PhN9es3lLOzs+rUqa/t27fazJuYaJWdHZFeVsdPGAAAAAAAABli/fp1Klu2mG7cuGFM27dvj9zd3eXp6akVK5ZqyJB35eTkJC8vL8XExOjXX39WnTp1ZbVaVbVqZZtxY69fv65jx46pdOkyybaVNEbtpUtRxrTnnmtpDHkgSYmJidq/f59Kly6jxMREPf98a+3du1deXl5ycnLSjz+uVeXKfjZBb5IPPhiltm1b2Uz788+9KlXqdl8CAqpq27b/B64REacUEXFKAQFVk61r0qRx6t9/oCTJYrFTYmKiJCk+Pj7Z8AhRUReVP3/y4BdZC6EtAAAAAAAAMkS1atWVM6ez+vYN0ZEjh/XTT//RiBFDFRz8liSpZMlS+uyzT7Vq1bc6duyIevbsqkKFfPTUU0/LYrGoSZOmGj9+jH799RcdOPCXgoO7q1ChQmrc+Olk2ypc2EceHh7av3+fMe3pp5vrk0/C9MMPa3TkyGENHNhPV65c0UsvvSI7Ozs5O+fSwIEDdfToEa1Zs0oTJ36gN9/sbywfGRmp6OhoSVLTps21detmzZgxVX//fUzz5s3RV199qV69ekuSXnutq5YuXayFCxfozz/3KSSkh55+upmKFStu089fftmkPHnyyM/PX5Lk7/+kvvvuax048Jf+85/vFRhYzWb+v/76U5Ur+z3yzwLmRmgLAAAAAACADOHi4qolS1YqMvKimjSpr7feClGHDq8pJORNSZKfn7/Gj/9QoaGD1bhxfUnSokVLjeEAhg17X0FBrdWzZ1c1a9ZQ8fFxWrRomezt7ZNty2KxqH79Rtq27TdjWs+ewQoJeVPvvTdADRvW0sGDB7Rs2bfG2LITJkyRvb29nnqqnoYPf09jx05Qy5bPGMs3bdpAYWFTJUn+/gGaO/dzLV26WPXr19CcOR9r5sy5qlq1uiSpatXqmjjxI02c+IFatmyivHnd9NFHYcn6eedVtpLUrVsP5cqVSy1bNlHt2nXVqtVzRtuRI4cVHR2tWrXqPtwPAI8Ni/Xua6xhiIy8poz4dOzsLLp2zVmhoValMAQLsihHRwfFxsZndjeQQQoWlEJDLXJ1jVFiYvY57XJ+y544v2UfmXFus1gkT8/kDwLBvWVUTYvsJ+n7yDEGwMx+/fUXvfVWsHbs2JOq+c1+bpswYaxOn47Qhx9Oz+yu4CGltp51yIC+AAAAAAAAPLYsFovueG4WHiN169aTt7e3fv55gxo0aPSv8yf9nO3sLKYLbePi4rRs2RItWvSV7Ow4INOS1apkYwdnNkJbAAAAAACAe7BYLMqT85Ysidczuyt4SGEfjtDb7wxXqyZV/nVeiyTduKI8DgkyV4Qnzf58odq2bqqACl6Sov51fqSe1S63rt50MlVwS2gLAAAAAABwDxaLZEm8LuvB6bLejMzs7uAhVJL049gKStwd+q/zWiQph70S48wX2nYNkBSgVO0HUs+S01OWsiGyWJxMdXU1oS0AAAAAAMC/sN6MlGJ4UEO2kOAg8YyGbMOq/4X1JmOX2R0AAAAAAAAAAPwfoS0AAAAAmNzLL7dT7949babt3btbzZo1VLFi3nr66fravfsPm/ZSpYoof/48Nq/o6Oh7buPAgb/03HMtk00PD9+hAgXc9M8/J4xpVqtVI0cOl5eXl0qXLqoRI4YqMTHxnusePPidZH2ZO/cTo33FiqWqWrWyihXzVqdOL+vixYtG26pV36pSpdKqUqW81q793ma9zZo11N69u22mff75fI0ZM/KefQEA4HFAaAsAAAAAJrZy5TKtW/cfm2nXr19X+/btVL16Lf3448+qWrW6Xn75eV2/fvtBSWfOnNbVq1e0fftu7d172Hjlzp37ntsZOLCf+vV712ZaXFyc+vbtkyyQnTlzulasWKqVK1dq3rwvtHz5V5o5c/o9133w4EENGRJq05f27TtIknbu/F1vvx2i/v0Has2an3TlymX16XM7oE5ISFD//n0UGjpK7703TG+++YbxkJh169Yqf/4C8vX1s9lW+/avavXqb3X06OH7fawAAJgaoS0AAAAAmNSlS1EaMWKo/P2ftJn+zTcrlDOns0JDR6lMmbIaNWqcXFxc9N13X0uSDh06KG/vAipe/Al5e3sbL4sl5VH7tm79VefPn1OdOvVspk+fPkWurq7J5p89e6befXew6tSpozp16mno0BH69NNZ99yPw4cPytfXz6YvuXLlkiTNnTtLrVo9pxdffFkVK1bSjBmztG7df3TixHFdvHhRUVFRatXqObVu3UZRUVGKjLz9IKhJk8ZpwICBybbl4OCgF198RdOmTblnfwAAMDtCWwAAAAAwqdDQIXr++ZdUpkw5m+nh4TtUvXoNI4S1WCyqVq2GduzYLkk6dOiASpYslertzJ8/R82bB9lMO3r0sD79dLZGjBhtM/3s2TOKiDilmjVrGdOqV6+pkyf/0blzZ5Ot+9q1qzpz5vQ9+xMevkM1a9Y23hcu7CMfnyIKD98hDw8P5cqVS3v27NLu3buUK1duubu7a/36H+XllT/ZVbZJmjVroZUrl+nKlcup/QgAADAVQlsAAAAAMKFfftmkrVt/Vd++7yRrO3furAoUKGgzzcsrv86ciZAkHTp0SDExN/Tssy1UqVJptW/f9p7DBVitVm3cuF716ze0mdav35saMGCQvLzyJ9u2JJvtJ81z+nREsvUfOnRQFotFU6ZMlJ9fOTVoUEuLFy+8Y33nVKBAgbv2xUunT5+Wvb29hg4doVatmqlNm5YaOXKM7O3tNXHiOA0YMCjF/ZGkMmXKys0tn7Zu3XLPeQAAMDNCWwAAAAAwmZs3b6p//zf1wQeT5OzsnKw9JiZGjo6ONtMcHR1161asJOnIkUO6dOmS3n57gBYs+FI5czqrbdtWio6+lmxd//xzQpcuXVKZMmWNaQsXLlBcXJw6dHgtxW1LkpOTkzEt6d9J27/T4cOHZLFYVKpUGS1atEyvvtpR/fu/qdWrv/vf+m7I0dHJZhlHRyfFxt6SJHXt2kOHDp3QgQPH1bFjZ23Y8JM8PT1VokQpdevWSf7+FTR06CBjrNskZcqU1Z49u5L1BwCAx4FDZncAAAAAAGBr4sQPVKWKvxo1apxiu5OTk2JjbQPS2NhY5cp1O+BdvHiF4uLi5OLiIkmaOXOO/P3La+3a79W27Qs2y128eHuMWHd3D0m3r3wdM2akli//LsUxcP8f0N4ypiX9O2n7d3rxxZfVtGlz5cvnLkmqWLGSjh49ovnz56hly2eUM2dOI6D9/77ckrNzLuO9i8v/x9WdNGmcxowZr7lzZyk+Pl5btoSrdetmWrXqWz3zTGtjPnd3d0VGXkj+4QEA8BjgSlsAAAAAMJmvv16u779freLFC6p48YJavvwrLV/+lYoXvz0kQcGChXT+/DmbZc6fP6f8+W8PM+Dk5GQEtpKUM2dOFS1aTGfOnEm2raRgNiEhQZK0YcM6RUVdVPPmT6l48YKqV6+6JKleveqaMmWiChYsZGzvzm1Lkre37TAHSetPCmyTlC5dVmfP3u5LgQIFdf78+bv25by8vb2TrWvTpg3Kly+fKleuoh07flP9+g3l7OysOnXqa/v2rTbzJiZaZWfHr7wAgMcT/4MBAAAAgMmsXLlaGzdu1fr1m7V+/WY1bdpCTZu20Pr1myVJAQFVtWPHNmNIAKvVqu3bf1NgYFVZrVZVrVrZZtzY69ev69ixYypdukyybSWNR3vpUpQkKSiolbZsCTe2vWjRMknSokXL1KlTFxUoUFA+PkW0bdv/Q9Jt27bKx6dIiqHtBx+MUtu2rWym/fnnXpUqVcbYlzvXFRFxShERpxQQUDXZuiZNGqf+/QdKkiwWOyUmJkqS4uPjkw2PEBV1UfnzJw9+AQB4HDA8AgAAAACYTJEiRW3eJ101W6JESUnSM8+01qhRwzVkyLvq2LGLFiz4VDdu3FCrVs/JYrGoSZOmGj9+jIoUKSoPD0998MEoFSpUSI0bP51sW4UL+8jDw0P79+9ToUKF5eLiajMcgYPD7V8bfXyKGFfMvvZaV40cOVzly5fWlSs3NGpUqN54o7exTGRkpHLmzCkXFxc1bdpcU6dO1owZU9WiRZA2blyvr776UitWrDLW9dxzLRUYWE1VqjypIUPe1dNPN1OxYsVt+vnLL5uUJ08e+fn5S5L8/Z/Ud999rdq16+o///leAwcOsZn/r7/+1BtvhDzwZw8AgBlwpS0AAAAAPGZcXfPoiy++0m+/bVWTJvUUHr5DX365TLlz55YkDRv2voKCWqtnz65q1qyh4uPjtGjRMtnb2ydbl8ViUf36jbRt22+p3n5w8Jt69tk2eu6559S1a0c9//xL6tkz2Ghv2rSBwsKmSpL8/QM0d+7nWrp0serXr6E5cz7WzJlzVbXq7WEXqlatrokTP9LEiR+oZcsmypvXTR99FJZsm3deZStJ3br1UK5cudSyZRPVrl1XrVo9Z7QdOXJY0dHRqlWrbqr3CQAAM7FY776HBIbIyGvKiE/Hzs6ia9ecFRpqVQpDTCGLcnR0UGxsfGZ3AxmkYEEpNNQiV9cYJSZmn9Mu57fsifNb9pEZ5zaLRfL0dP33GWHIqJpWuh3+pfDcKjwGNm/+RW+9Fazff9+T6mUsFsnd3UVRUdEZdoyl1vjxYxURcUoffTQjs7uSpVitSjYMRXZgZ2dRnhxRStwdKsVQ1GZ1Fv2/ns1+R3s25VxQdn6huhrnniE1bWrrWYZHAAAAAPDILBaL8uS8JUvi9czuCh5Ci4YVNc7bXdt/+UaNG6Xu6lSLJN24ojwOCaYKNuLi4rR86UKt/OpT5ckRldndyVKsdrl19aZTtgxuASCjEdoCAAAAeGQWi2RJvC7rwemy3ozM7O7gIUzt6aO3Q/upkUeLVM1vkaQc9kqMM1do++k3B/RczTwqE/OFEndndm+yDktOT1nKhshicTLdldUAkBUR2gIAAABIM9abkdw+/JjyLSStG+//YD+/BAfJZEPivP50Xkl5OQ7TmFX/C+oBABmCB5EBAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAA/Le9u4+psu7jOP45HAwoxR20USARuMlMsIEPwIKa6Bqu2JylPQnlao0NU2YQi1AJRA1WuTSkpTRtjD9IoLDlGEu21pCQJfaA5GyGShAjScajcLj/aJ47ZnEj3ZxznXPer3/g/M51uL6XGz8++xy5AAAAAAADobQFAAAAAAAAAAOhtAUAAAAAAAAAA6G0BQAAAAAAAAADcdnSdnh4WNnZ2Vq+fLni4uJUWlrq6JEAAACA20KmBQAAcE+ejh5gphQWFur777/X0aNH1dHRoaysLAUEBCgxMdHRowEAAABTQqYFAABwTy5Z2g4MDKiiokIffvihlixZoiVLlujChQsqKysj4AIAAMApkGkBAADcl0veHuH8+fMaHR1VZGSkbW3ZsmVqaWmR1Wp14GQAAADA1JBpAQAA3JdLlrbd3d2yWCy64447bGvz58/X8PCwent7HTcYAAAAMEVkWgAAAPflkrdHGBwcnBBuJdkej4yMTPnreHhI4+P/19H+lsn057kWLDDJ29sOJ4QhzJol3bjh6ClgL/Pnm+Th8d/vd3fB/uae2N/chyP2NpPJPucxAmfMtCaZ5HFnoMbN3jN/QjieSZKnWfIak4kf8y7P5DVPJpncLs9K7G9uh73N7dh7f5tqnnXJ0tbLy+uWIHvzsbf31DdYP785/9e5Jj+XtHu33U4Hw3DJb0FMarajB7A79jd3xf7mXtxvb7MHZ8y00mxpWb4dzwcjuON/HwIX4ufoARyG/c3dsLe5H6Ptby75/pi/v7+uXbum0dFR21p3d7e8vb3l6+vrwMkAAACAqSHTAgAAuC+XLG0XL14sT09PnT171rbW3NysiIgIebjb73EAAADAKZFpAQAA3JdLpj0fHx+tW7dOubm5OnfunOrq6lRaWqqUlBRHjwYAAABMCZkWAADAfZnGx+3xZwnsb3BwULm5uaqtrdXs2bP14osv6oUXXnD0WAAAAMCUkWkBAADck8uWtgAAAAAAAADgjFzy9ggAAAAAAAAA4KwobQEAAAAAAADAQChtAQAAAAAAAMBAKG2BGRIWFqZXX331lvXKykolJCQ4YCIAmJ7t27frkUce0eDg4C3Pbd68WU8//bS4RT4AuCYyLQBXQaaFs6G0BWbQiRMn1NDQ4OgxAOBfycrKUl9fn0pKSias19bWqqmpSXl5eTKZTA6aDgAw08i0AFwBmRbOhtIWmEGBgYHKy8vTyMiIo0cBgGnz9/fXK6+8oo8++kiXL1+WJA0NDWnfvn3avHmzFi1a5OAJAQAziUwLwBWQaeFsKG2BGZSenq6uri4dOXLkH4/p7OzUtm3btHLlSkVHR2v37t0EYgCGk5ycrODgYBUVFUmSDh8+LA8PD6WlpenXX39VamqqHnzwQSUkJOjgwYMaGxuTJN24cUM5OTmKjo5WZGSkUlNT1dXV5chLAQDcJjItAFdBpoUzobQFZpC/v7+2bt2qkpIS2zt5fzUyMqLnn39eg4OD+vjjj7V//37V19ersLDQAdMCwD/z9PTUzp07VVtbq7q6Oh05ckS7du2Sl5eXtmzZonnz5qmqqkp79+5VTU2N7dfOysrK1NTUpNLSUn3yySfq7+/Xnj17HHw1AIDbQaYF4CrItHAmlLbADLv5Tl5BQcEtz3311Vfq6upSUVGRwsLCFBsbq507d6q8vFz9/f0OmBYA/tmKFSuUlJSkbdu2adWqVYqPj9fp06fV0dGh/Px8hYaGKjo6WllZWTp27Jgk6cqVK/Ly8lJgYKAWLlyoffv26eWXX3bwlQAAbheZFoCrINPCWXg6egDA1ZnNZuXm5urZZ59VXV3dhOcuXryo+++/X3PnzrWtRUVFaXR0VO3t7Vq8eLG9xwWASaWmpuqzzz5TWlqapD/3sd7eXi1btsx2jNVq1dDQkK5du6annnpKn3/+ueLi4rRy5UqtWbNG69evd9T4AIBpItMCcCVkWjgDSlvADqKiovTEE0+ooKBAL730km3dy8vrlmNv3jPn5kcAMJKb+9bNj6OjowoNDVVxcfEtx86ZM0cWi0Vffvml6uvrVV9fr3feeUcnTpxQWVkZf50XAJwMmRaAqyDTwhlwewTATjIyMjQwMDDhDziEhITo0qVL6u3tta2dPXtWnp6euu+++xwwJQDcnpCQEHV0dMjPz0/BwcEKDg7WlStX9N5778lkMqm6ulqnTp3S2rVr9dZbb+nw4cNqbm5WT0+Po0cHAEwDmRaAKyLTwogobQE7sVgsysjI0NWrV21rDz30kIKCgvTaa6+pra1Np0+fVn5+vh5//HH5+vo6cFoAmJq4uDgFBgYqMzNTbW1tOnPmjHbs2CEfHx+ZzWb19fWpoKBADQ0Nunz5smpqanTPPffIYrE4enQAwDSQaQG4IjItjIjbIwB29OSTT+r48eP67bffJP15b7Di4mLl5+dr48aNuuuuu5SUlKTt27c7eFIAmBqz2axDhw7Z9rE777xTiYmJysrKkiQ999xz6uzsVGZmpv744w+Fh4fr0KFDMpvNDp4cADBdZFoAroZMCyMyjY+Pjzt6CAAAAAAAAADAn7g9AgAAAAAAAAAYCKUtAAAAAAAAABgIpS0AAAAAAAAAGAilLQAAAAAAAAAYCKUtAAAAAAAAABgIpS0AAAAAAAAAGAilLQAAAAAAAAAYCKUtAAAAAAAAABgIpS0AGFBYWJgaGxun9drk5GQdOHBgWq9tbGxUWFjYtF4LAAAA/BWZFgCmj9IWAAAAAAAAAAyE0hYAAAAAAAAADITSFgCczPj4uEpKSpSQkKDw8HDFxcXp4MGDE47p7OzUpk2bFBERoY0bN+r8+fO2565fv67MzExFRUUpLi5O+fn5Ghoa+ttzHTt2TKtWrVJERITWr1+vM2fOzOi1AQAAwD2QaQFgcpS2AOBkqqurdfToURUUFOjkyZNKS0vTgQMH9MMPP9iOqaqqUmJioqqrqxUUFKQtW7ZobGxMkvTGG2+or69P5eXlKi4u1nfffae8vLxbzvPjjz+qsLBQu3bt0hdffKHly5crPT1dVqvVbtcKAAAA10SmBYDJUdoCgJO59957tXfvXsXGxmrBggV65plndPfdd+vChQu2Y9asWaNNmzZp4cKFevPNN9XT06Ovv/5a7e3tqqurU1FRkcLCwrR06VLl5+erqqpKfX19E85z9epVmUwmBQQEaMGCBUpPT1dRUREBFwAAAP8amRYAJufp6AEAALcnJiZGLS0tevvtt3Xx4kW1traqu7t7QvBcunSp7fPZs2crJCREP//8s8bGxmS1WvXwww9P+JpWq1W//PLLhLW4uDgtWrRISUlJeuCBB7R69Wpt2LBBnp786AAAAMC/Q6YFgMmxSwGAk6moqNCePXu0YcMGPfroo8rKylJKSsqEY8xm84THVqtVs2bN0tjYmObMmaPjx4/f8nX9/f3V0tJie+zj46OKigp98803OnXqlCorK1VeXq7Kykr5+/vPzMUBAADALZBpAWBy3B4BAJxMeXm50tLSlJ2drXXr1slisainp0fj4+O2Y3766Sfb59evX9elS5cUGhqqkJAQ9fX1yWQyKTg4WMHBwRoaGlJhYaFGRkYmnOfbb7/VBx98oJiYGL3++us6efKkhoeH1dzcbLdrBQAAgGsi0wLA5PiftgBgUOfOndPw8PCEtRUrVshisaihoUGrV69Wf3+/3n33Xd24cWNCQK2pqVFkZKSioqK0f/9+BQcHKyYmRiaTSfHx8crIyFBOTo7MZrN27NihuXPnytfXd8K5vL299f7772v+/PmKjY1VU1OTBgYGFBYWZpfrBwAAgPMj0wLA9JjG//o2FgDAEP4pRNbW1mp0dFTZ2dlqbW3VvHnztHbtWrW3t8vPz095eXlKTk5WeHi4mpub1draqsjISBUUFCgoKEiS9Pvvv2v37t2qr6+Xp6en4uPjlZOTI4vFosbGRqWkpKitrU2S9Omnn6q4uFgdHR0KCAjQ1q1b9dhjj9nt3wEAAADOi0wLANNHaQsAAAAAAAAABsI9bQEAAAAAAADAQChtAQAAAAAAAMBAKG0BAAAAAAAAwEAobQEAAAAAAADAQChtAQAAAAAAAMBAKG0BAAAAAAAAwEAobQEAAAAAAADAQChtAQAAAAAAAMBAKG0BAAAAAAAAwEAobQEAAAAAAADAQChtAQAAAAAAAMBAKG0BAAAAAAAAwED+A2wDYxxj0BCXAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "The percentage of yes answers in each data split is: Train; 62.64%, Val; 59.50%, Test;62.17%\n",
    "Seeing how difficult it was in past projects to reach a much better accuracy than the baseline majority class I am setting my goal for the transformer model at 64% accuracy on the test set.\n",
    "\n",
    "### Metrics\n",
    "**Accuracy**: To evaluate model performance across different hyperparameter configurations, I will use validation accuracy as the primary metric.\n",
    "**Confusion Matrix**: This will give a comprehensive view of true positives, true negatives, false positives, and false negatives, allowing me deeper insight into the model’s performance.\n",
    "\n",
    "### Error Analysis\n",
    "To understand why the model may fail on certain predictions, I will conduct an error analysis investigating weather missclassifications are related to the confidence score the model has in it's predictions. Low confidence on correct answers or high confidence on wrong answers may indicate areas where the model is uncertain or overconfident."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## <span style=\"color: orange;\">Evaluation</span>\n",
    "Choosing to do without any manual preprocessing and relying on the built-in functionality of the AutoTokenizer module to handle padding, truncation, extra whitespace removal, special character removal and case sensitivity management was a success. Making the implementation more straightforward and reducing the potential for implementation errors. In most of my runs the transformer model would reach a validation accuracy of ~59%, after plotting the distribution of labels in the validation set it was clear to me the model is only predicting the majority \"yes\" class. After this realization I added the dropout layer and weight decay to the model which showed improvement in reaching a better validation accuracy, now reaching 60%. <br>\n",
    "For my evaluation on the test set I chose the model reaching the highest accuracy on the validation set.\n",
    "### Results of test set validation\n",
    "Run name: emb_dim_256-n_heads_8-trans_h_dim_512-class_h_dim_128-dropout_0.2-lr_0.0001-warmup_100-w_decay_0.0001 <br>\n",
    "Test Accuracy: 63.70%\n",
    "True Positives: 1880\n",
    "True Negatives: 203\n",
    "\n",
    "The model reached an accuracy of 63.70% on the test set compared to the baseline of 62.17%, however it still predominantly predicts the majority class. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T20:54:18.809811Z",
     "start_time": "2024-11-11T20:54:11.069588Z"
    }
   },
   "source": [
    "# Define paths and load model from checkpoint\n",
    "base_path = Path(\"checkpoints\")\n",
    "run_name = \"emb_dim_256-n_heads_8-trans_h_dim_512-class_h_dim_128-dropout_0.2-lr_0.0001-warmup_100-w_decay_0.0001\"\n",
    "file_path = base_path / (run_name + \".ckpt\")\n",
    "\n",
    "# Load the model from the checkpoint\n",
    "model = TransformerClassifier.load_from_checkpoint(file_path)\n",
    "wandb_logger = WandbLogger(project=\"nlp_p3_transformer\", name=run_name, group=\"evaluation\")\n",
    "\n",
    "# Initialize the trainer for testing\n",
    "trainer = pl.Trainer(logger=wandb_logger)\n",
    "trainer.test(model, test_loader)\n",
    "\n",
    "# Finish WandB session\n",
    "wandb.finish()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pascal\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20241111_215411-45dfduoe</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aintnoair/nlp_p3_transformer/runs/45dfduoe' target=\"_blank\">emb_dim_256-n_heads_8-trans_h_dim_512-class_h_dim_128-dropout_0.2-lr_0.0001-warmup_100-w_decay_0.0001</a></strong> to <a href='https://wandb.ai/aintnoair/nlp_p3_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aintnoair/nlp_p3_transformer' target=\"_blank\">https://wandb.ai/aintnoair/nlp_p3_transformer</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aintnoair/nlp_p3_transformer/runs/45dfduoe' target=\"_blank\">https://wandb.ai/aintnoair/nlp_p3_transformer/runs/45dfduoe</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\Pascal\\miniconda3\\envs\\nlp\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pascal\\AppData\\Local\\Temp\\ipykernel_23712\\1889658370.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = [torch.tensor(item['input_ids']) for item in batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 52/52 [00:04<00:00, 12.33it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "      test_accuracy         0.6370030641555786\r\n",
      "        test_loss           0.6468071937561035\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>test_accuracy</td><td>0.637</td></tr><tr><td>test_loss</td><td>0.64681</td></tr><tr><td>trainer/global_step</td><td>0</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">emb_dim_256-n_heads_8-trans_h_dim_512-class_h_dim_128-dropout_0.2-lr_0.0001-warmup_100-w_decay_0.0001</strong> at: <a href='https://wandb.ai/aintnoair/nlp_p3_transformer/runs/45dfduoe' target=\"_blank\">https://wandb.ai/aintnoair/nlp_p3_transformer/runs/45dfduoe</a><br/> View project at: <a href='https://wandb.ai/aintnoair/nlp_p3_transformer' target=\"_blank\">https://wandb.ai/aintnoair/nlp_p3_transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241111_215411-45dfduoe\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "My expectation for this project are to beat the majority class baseline of 62.17% on the test set. My last project wasn't very successufl in that it only predicted the majority class every time. The feedback on that project was plenty and I hope I can improve on a lot of points for this project.\n",
    "\n",
    "Given the results form the LSTM implementation I am setting my expecation for the Transformer architecture to reach an accuracy of 63% to 65% on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
