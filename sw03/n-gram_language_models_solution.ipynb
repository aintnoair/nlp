{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c46cbd05",
   "metadata": {},
   "source": [
    "# N-Gram Language Models\n",
    "In this exercise, we will use n-gram language models to predict the probability of text, and generate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8dd1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08771f",
   "metadata": {},
   "source": [
    "First, we load Jane Austen's Emma from NLTK's gutenberg corpus that we also used in a previous exercise. Tokenize and lowercase this text such that we have a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a90fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158167\n"
     ]
    }
   ],
   "source": [
    "raw_text = gutenberg.raw('austen-emma.txt')\n",
    "words = [w.lower() for w in raw_text.split()]\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60adf6a1",
   "metadata": {},
   "source": [
    "Write an n-gram language model class that takes the word list and a parameter `n` as inputs, where `n` is a positive integer larger than 1 that determines the `n` of the n-gram LM. The LM should build a dictionary of n-gram counts from the word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9635e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class NGramLanguageModel:\n",
    "    \n",
    "    def __init__(self, words, n=2):\n",
    "        assert n > 1, \"n needs to be a positive integer > 1\"\n",
    "        assert n <= len(words), \"n can't be larger than the number of words\"\n",
    "        self.n = n\n",
    "        self.counts = defaultdict(int)\n",
    "        for i in range(len(words) - self.n + 1):\n",
    "            ngram = tuple(words[i:i+self.n])\n",
    "            self.counts[ngram] += 1\n",
    "            self.counts[ngram[:-1]] += 1\n",
    "        self.counts[ngram[1:]] += 1  # last n-gram in the input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c2d523",
   "metadata": {},
   "source": [
    "Now we \"train\" the n-gram LM by building the n-gram counts of the Emma novel. Use a low `n` (i.e. 2 or 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b49ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = NGramLanguageModel(words, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7bf596",
   "metadata": {},
   "source": [
    "Let's add a method `log_probability` to the n-gram LM class that computes the probability of an input string. Since multiplying many probabilities (<= 1) results in very small numbers that can underflow, we sum the log probabilities instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1cfa205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def log_probability(self, input_string):\n",
    "    log_prob = []\n",
    "    words = [w.lower() for w in input_string.split()]\n",
    "    for i in range(len(words) - self.n + 1):\n",
    "        ngram = tuple(words[i:i+self.n])\n",
    "        if ngram in self.counts:\n",
    "            prob = self.counts[ngram] / self.counts[ngram[:-1]]\n",
    "            log_prob.append(math.log(prob))\n",
    "    return sum(log_prob)\n",
    "\n",
    "NGramLanguageModel.log_probability = log_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd5d8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.159484249353372\n",
      "-5.049856007249537\n"
     ]
    }
   ],
   "source": [
    "print(ngrams.log_probability('There is a house in New Orleans.'))\n",
    "print(ngrams.log_probability('There is a house in New Orleans. '\n",
    "                             'And then there are also many other houses in many other cities.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e7469",
   "metadata": {},
   "source": [
    "Shorter texts will have higher log probability than longer texts, so we need to normalize it by the number of words in the input string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0338f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_probability(self, input_string):\n",
    "    log_prob = []\n",
    "    words = [w.lower() for w in input_string.split()]\n",
    "    for i in range(len(words) - self.n + 1):\n",
    "        ngram = tuple(words[i:i+self.n])\n",
    "        if ngram in self.counts:\n",
    "            prob = self.counts[ngram] / self.counts[ngram[:-1]]\n",
    "            log_prob.append(math.log(prob))\n",
    "    return np.mean(log_prob)\n",
    "\n",
    "NGramLanguageModel.log_probability = log_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e2054",
   "metadata": {},
   "source": [
    "Lets predict the probabilities of two novels under our trained model: Jane Austen's *Sense and Sensibility* (`austen-sense.txt`) and Shakespeare's *Hamlet* (`shakespeare-hamlet.txt`).\n",
    "- What do you expect will happen?\n",
    "- What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4dc2cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.159484249353372\n",
      "-2.142628255277218\n",
      "-2.2824723388271106\n"
     ]
    }
   ],
   "source": [
    "austen_sense = gutenberg.raw('austen-sense.txt')\n",
    "shakespeare_hamlet = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "print(ngrams.log_probability('There is a house in New Orleans.'))\n",
    "print(ngrams.log_probability(austen_sense))\n",
    "print(ngrams.log_probability(shakespeare_hamlet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002ddb4",
   "metadata": {},
   "source": [
    "How many n-grams are known in each input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2adcafb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known n-grams in Sense and Sensibility: 15.10% (17925/118673)\n",
      "Known n-grams in Hamlet: 3.06% (906/29603)\n"
     ]
    }
   ],
   "source": [
    "def known_ngrams(self, input_string):\n",
    "    known = 0\n",
    "    words = [w.lower() for w in input_string.split()]\n",
    "    for i in range(len(words) - self.n + 1):\n",
    "        ngram = tuple(words[i:i+self.n])\n",
    "        if ngram in self.counts:\n",
    "            known += 1\n",
    "    return known, len(words) - self.n + 1\n",
    "\n",
    "NGramLanguageModel.known_ngrams = known_ngrams\n",
    "known, total = ngrams.known_ngrams(austen_sense)\n",
    "print(f'Known n-grams in Sense and Sensibility: {known/total:.2%} ({known}/{total})')\n",
    "known, total = ngrams.known_ngrams(shakespeare_hamlet)\n",
    "print(f'Known n-grams in Hamlet: {known/total:.2%} ({known}/{total})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be2adf0",
   "metadata": {},
   "source": [
    "Let's add a method `generate` that takes the start of a sentence (\"prompt\") and a number of words to generate, then continues our prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9975c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(self, prompt, num_words=10):\n",
    "    words = [w.lower() for w in prompt.split()]\n",
    "    for i in range(num_words):\n",
    "        prefix = tuple(words[-(self.n - 1):])\n",
    "        if prefix not in self.counts:\n",
    "            words.append('[END]')\n",
    "            break\n",
    "        next_word_dist = {}\n",
    "        for ngram in self.counts:\n",
    "            if len(ngram) == self.n and ngram[:-1] == prefix:\n",
    "                next_word_dist[ngram] = self.counts[ngram] / self.counts[prefix]\n",
    "        # print(prefix, next_word_dist)\n",
    "        best_ngram, prob = max(next_word_dist.items(), key=lambda x: x[1])\n",
    "        print(best_ngram, prob)\n",
    "        words.append(best_ngram[-1])\n",
    "    return ' '.join(words)\n",
    "\n",
    "NGramLanguageModel.generate = generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd049682",
   "metadata": {},
   "source": [
    "Play around with a few different prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d951f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'walk', 'with') 0.3333333333333333\n",
      "('walk', 'with', 'her,') 0.5\n",
      "('with', 'her,', 'but') 0.21052631578947367\n",
      "('her,', 'but', 'emma') 0.2\n",
      "('but', 'emma', 'could') 0.5\n",
      "('emma', 'could', 'not') 0.576271186440678\n",
      "('could', 'not', 'be') 0.16605166051660517\n",
      "('not', 'be', 'in') 0.03496503496503497\n",
      "('be', 'in', 'a') 0.12121212121212122\n",
      "('in', 'a', 'very') 0.056179775280898875\n",
      "('a', 'very', 'good') 0.11413043478260869\n",
      "('very', 'good', 'sort') 0.11904761904761904\n",
      "('good', 'sort', 'of') 1.0\n",
      "('sort', 'of', 'thing') 0.047619047619047616\n",
      "('of', 'thing', 'that') 0.5\n",
      "('thing', 'that', 'is') 0.13636363636363635\n",
      "('that', 'is', 'quite') 0.1\n",
      "('is', 'quite', 'a') 0.21052631578947367\n",
      "('quite', 'a', 'different') 0.23809523809523808\n",
      "('a', 'different', 'sort') 0.058823529411764705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i went for a walk with her, but emma could not be in a very good sort of thing that is quite a different sort'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams.generate(\"I went for a walk\", num_words=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
