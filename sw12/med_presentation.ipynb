{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-04T08:25:21.725621Z",
     "start_time": "2024-12-04T08:24:41.710012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings using PubMedBERT...\n"
     ]
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7750a75445214facb3469ff38fe63321"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fd936fc9731404bb4e421c1cd97a076"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5884d3982d274a0fb6d554348004d649"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3fb9ec6ed5d44d11bfb175628421e78b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings using BioBERT...\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1dad78fe2f9486290a0e494c4ad1b77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d05aec2f94d24f70b5c03bcbf1081b83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3819cdc4e3af41ae856423f6ef398f79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings using SBERT...\n"
     ]
    },
    {
     "data": {
      "text/plain": "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd2de73be5774b1f9752cc38caca874c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9924394a40de49dcb490a0caa1860544"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f41b867d26bf4327a56097e259094bc4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4be051c6e594b50bf580baca38285c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2029be45d3e04c91a1cdfd24b290c915"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26ccbfdb814b4a07a3e70dff4a15021b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed76cebd7a8c40bc970f368cb1a08ef9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2324a2f5e184c4faf44e897571cbe0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3bccae606a4409ba4ca15c4893b7d64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a79ffd5ac63747cb8c0468d08aaba89e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80278818816f4f26a59c3c35c59a1adc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarity:\n",
      "Terms: hyperkalemia vs hypermetropia\n",
      "  PubMedBERT: 0.9251\n",
      "  BioBERT: 0.9168\n",
      "  SBERT: 0.4888\n",
      "Terms: hyperkalemia vs eye disease\n",
      "  PubMedBERT: 0.8716\n",
      "  BioBERT: 0.8752\n",
      "  SBERT: 0.1756\n",
      "Terms: hypermetropia vs eye disease\n",
      "  PubMedBERT: 0.9037\n",
      "  BioBERT: 0.9315\n",
      "  SBERT: 0.2563\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the terms\n",
    "terms = [\"hyperkalemia\", \"hypermetropia\", \"eye disease\"]\n",
    "\n",
    "# Function to calculate embeddings\n",
    "def calculate_embeddings(model_name, tokenizer_name, terms):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    embeddings = []\n",
    "    \n",
    "    for term in terms:\n",
    "        inputs = tokenizer(term, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        # Use the [CLS] token's embedding for simplicity\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings.append(cls_embedding.squeeze(0))\n",
    "    return embeddings\n",
    "\n",
    "# Function for cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return F.cosine_similarity(vec1.unsqueeze(0), vec2.unsqueeze(0)).item()\n",
    "\n",
    "# Generate embeddings using PubMedBERT\n",
    "print(\"Generating embeddings using PubMedBERT...\")\n",
    "pubmedbert_embeddings = calculate_embeddings(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\", \n",
    "                                              \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\", terms)\n",
    "\n",
    "# Generate embeddings using BioBERT\n",
    "print(\"Generating embeddings using BioBERT...\")\n",
    "biobert_embeddings = calculate_embeddings(\"dmis-lab/biobert-base-cased-v1.1\", \n",
    "                                           \"dmis-lab/biobert-base-cased-v1.1\", terms)\n",
    "\n",
    "# Generate embeddings using SBERT\n",
    "print(\"Generating embeddings using SBERT...\")\n",
    "sbert_model = SentenceTransformer(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "sbert_embeddings = [sbert_model.encode(term, convert_to_tensor=True) for term in terms]\n",
    "\n",
    "# Calculate cosine similarity for pairs of terms\n",
    "print(\"\\nCosine Similarity:\")\n",
    "for i in range(len(terms)):\n",
    "    for j in range(i + 1, len(terms)):\n",
    "        pubmedbert_sim = cosine_similarity(pubmedbert_embeddings[i], pubmedbert_embeddings[j])\n",
    "        biobert_sim = cosine_similarity(biobert_embeddings[i], biobert_embeddings[j])\n",
    "        sbert_sim = cosine_similarity(sbert_embeddings[i], sbert_embeddings[j])\n",
    "        \n",
    "        print(f\"Terms: {terms[i]} vs {terms[j]}\")\n",
    "        print(f\"  PubMedBERT: {pubmedbert_sim:.4f}\")\n",
    "        print(f\"  BioBERT: {biobert_sim:.4f}\")\n",
    "        print(f\"  SBERT: {sbert_sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7d1038a2951b6a85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
