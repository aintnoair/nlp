{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9683e0ef-8709-4440-8e4b-f65505a469bc",
   "metadata": {},
   "source": [
    "# Using Self-Hosted LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b0f23-550e-424c-b615-e71fccdcc4cb",
   "metadata": {},
   "source": [
    "## 1. Preliminary Setup and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f961de8-3607-4f35-8fb3-08d3253d7e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## install the Openai library\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26be73a0-be72-4056-a8db-5771bb4998f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "model_clients = {\n",
    "    \"llama-3.3-70b\": OpenAI(\n",
    "        api_key=\"empty\",\n",
    "        base_url=\"http://10.180.132.21:8189/v1\",\n",
    "    ),\n",
    "    \"hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4\": OpenAI(\n",
    "        api_key=\"empty\",\n",
    "        base_url=\"http://10.180.132.25:8188/v1\",\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f842035-83d3-473b-a3dc-fcaa13e748ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prompting helper function\n",
    "def run_prompt(prompt_messages, client, model_name):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=prompt_messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return  response.choices[0].message.content\n",
    "\n",
    "def prompt_models(prompt_messages, model_clients):\n",
    "    for model_name, client in model_clients.items():\n",
    "\n",
    "        response_message = run_prompt(\n",
    "            prompt_messages=prompt_messages, \n",
    "            client=client,\n",
    "            model_name=model_name\n",
    "        )\n",
    "        \n",
    "        print(\n",
    "        f\"\"\"\n",
    "            Model: {model_name}\n",
    "            Response: {response_message}\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530634ad-ce1b-41c1-adc8-5badedace50b",
   "metadata": {},
   "source": [
    "## 2. Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa8ce614-b4c0-421d-983b-8b88e5c16199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Model: llama-3.3-70b\n",
      "            Response: Pro\n",
      "        \n",
      "\n",
      "            Model: hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4\n",
      "            Response: Kontra\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "prompt_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Deine Aufgabe ist es die Haltung eines Textes gegenüber einem Thema zu bestimmen. Entweder unterstützt der Text das Thema oder nicht. Mögliche Antworten sind “Pro” oder “Kontra”.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"\n",
    "Thema: Befürworten Sie eine Erhöhung des Rentenalters?\n",
    "Text: Durch den demographischen Wandel hat das jetzige Rentenalter ein Ablaufdatum. Die Rentenversprechen können bald nicht mehr erfüllt werden. Je länger wir warten, die nötigen strukturellen Reformen vorzunehmen, desto teuerer wird es.\n",
    "        \"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt_models(prompt_messages, model_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2eae3a-c5ec-450c-909e-e3660a3518dd",
   "metadata": {},
   "source": [
    "### What are the reasons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29cca02-426a-42dd-9556-f16498db1a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Model: llama-3.3-70b\n",
      "            Response: Pro\n",
      "        \n",
      "\n",
      "            Model: hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4\n",
      "            Response: Pro\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "prompt_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Deine Aufgabe ist es die Haltung eines Textes gegenüber einem Thema zu bestimmen. Entweder unterstützt der Text das Thema oder nicht. Mögliche Antworten sind “Pro” oder “Kontra”. \"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"\n",
    "Thema: Befürworten Sie eine Erhöhung des Rentenalters?\n",
    "Text: Durch den demographischen Wandel hat das jetzige Rentenalter ein Ablaufdatum. Die Rentenversprechen können bald nicht mehr erfüllt werden. Je länger wir warten, die nötigen strukturellen Reformen vorzunehmen, desto teuerer wird es.\n",
    "        \"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "prompt_models(prompt_messages, model_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff97b68-c235-454d-bc82-594f846b9dab",
   "metadata": {},
   "source": [
    "## 3. Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b1f19b-a24c-44c1-a311-098262ce2cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Model: llama-3.3-70b\n",
      "            Response: Kontra\n",
      "        \n",
      "\n",
      "            Model: hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4\n",
      "            Response: Kontra\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "prompt_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Deine Aufgabe ist es die Haltung eines Textes gegenüber einem Thema zu bestimmen. Entweder unterstützt der Text das Thema oder nicht. Antworte nur mit einem Wort. Mögliche Antworten sind “Pro” oder “Kontra”.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"\n",
    "Thema: Befürworten Sie eine Erhöhung des Rentenalters?\n",
    "Text: Durch den demographischen Wandel hat das jetzige Rentenalter ein Ablaufdatum. Die Rentenversprechen können bald nicht mehr erfüllt werden. Je länger wir warten, die nötigen strukturellen Reformen vorzunehmen, desto teuerer wird es.\n",
    "        \"\"\"\n",
    "    },\n",
    "        {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Pro\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"\n",
    "Thema: Befürworten Sie engere Beziehungen zur Europäischen Union (EU)?\n",
    "Text: Der bilaterale Weg war und ist wichtig. Die EU verlangt im Moment aber auch eine institutionelle Integration. Diese lehne ich ab.\n",
    "        \"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt_models(prompt_messages, model_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6838bb-f9af-4cf4-b59a-f435ed4b80a1",
   "metadata": {},
   "source": [
    "## 4. Sociademographic Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b934f29-2567-49a5-a8a2-e3a0720c1a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Model: llama-3.3-70b\n",
      "            Response: Pro\n",
      "        \n",
      "\n",
      "            Model: hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4\n",
      "            Response: Pro\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "prompt_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Deine Aufgabe ist es die Haltung eines Textes gegenüber einem Thema zu bestimmen. Entweder unterstützt der Text das Thema oder nicht. Antworte nur mit einem Wort. Mögliche Antworten sind “Pro” oder “Kontra”.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"\n",
    "Person: Die Person ist 55 Jahre alt, männlich, studiert, und politische Prioritäten ist eine kommunistische Gesselschaft.\n",
    "Thema: Befürworten Sie eine Erhöhung des Rentenalters?\n",
    "Text: Durch den demographischen Wandel hat das jetzige Rentenalter ein Ablaufdatum. Die Rentenversprechen können bald nicht mehr erfüllt werden. Je länger wir warten, die nötigen strukturellen Reformen vorzunehmen, desto teuerer wird es.\n",
    "        \"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "prompt_models(prompt_messages, model_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d5dd4f-739d-4042-858c-4ffb29e0320d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
